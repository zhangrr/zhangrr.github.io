<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3988508441804851" crossorigin=anonymous></script><title>LibreChat如何配置接入Azure | 八戒的技术博客</title>
<meta name=keywords content><meta name=description content='Ai的时代已经来临，现在主用的是谷歌的antigravity，然后平时对话询问，用的是LibreChat，给个链接
https://github.com/danny-avila/LibreChat
然后这个东西吧，配起来没那么简单，还是 docker compose 的部署方法快捷
那有openrouter的api，这个接入简单。那同时之前还有用Azure gpt-4o的api，用的是Javis，直接接入Azure
Javis偏弱，现在想统一用到LibreChat，接入还真的是一言难尽
来详细说说Azure的配法，背景：Azure是同事在2024年开的，只给了我三个参数
AZURE_OPENAI_API_BASE="https://pppqqq-eus.openai.azure.com/"
OPENAI_API_KEY="12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M"
AZURE_OPENAI_DEPLOYMENT_NAME="gpt-4o-abc"
然后呢，同事还离职了，然后其它参数就都问不到了
LibreChat呢，文档简直稀烂，而且变动还特别大
LibreChat主要的思路呢，就是在.env中定义变量，然后在librechat.yaml中使用变量，我们就省了，都扔到librechat.yaml中好了
endpoints:
  azureOpenAI:
    titleModel: "gpt-4o"
    plugins: true
    groups:
      - group: "azure"
        apiKey: "12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M"
        instanceName: "pppqqq-eus"
        version: "2024-05-01-preview" # 推荐使用新版API，以支持GPT-4o
        # --- Model-Level Mapping (重点) ---
        models:
          # LibreChat显示的名称: 实际Azure部署的名称
          gpt-4o: # <--- 这个名称会显示在LibreChat的下拉菜单中
            deploymentName: "gpt-4o-abc" # <--- 您的实际Azure部署名称
            version: "2024-05-01-preview" # 可覆盖group的version
          gpt-4-turbo-2024-04-09: # LibreChat显示的名称
            deploymentName: "gpt-4o-abc" # 您的实际Azure部署名称
            version: "2024-02-15-preview"
上面的配置是问了gemini给出的，看得出来变量AZURE_OPENAI_API_BASE中的xxx.openai.azure.com前面的xxx，就是instanceName
OPENAI_API_KEY就是apiKey
AZURE_OPENAI_DEPLOYMENT_NAME就是deploymentName
模型的gpt-4o还有gpt-4-turbo-2024-04-09都是geimini给出的，version也很重要，不对会报错
然后就可以了'><meta name=author content><link rel=canonical href=https://rendoumi.com/posts/20251210-librechat_azure/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5d8a858b4ad07d913988e10d3c3dbc8c171f45316a396de8a60d67f44840812d.css integrity="sha256-XYqFi0rQfZE5iOENPD28jBcfRTFqOW3opg1n9EhAgS0=" rel="preload stylesheet" as=style><link rel=icon href=https://rendoumi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rendoumi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rendoumi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://rendoumi.com/apple-touch-icon.png><link rel=mask-icon href=https://rendoumi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://rendoumi.com/posts/20251210-librechat_azure/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rendoumi.com/posts/20251210-librechat_azure/"><meta property="og:site_name" content="八戒的技术博客"><meta property="og:title" content="LibreChat如何配置接入Azure"><meta property="og:description" content='Ai的时代已经来临，现在主用的是谷歌的antigravity，然后平时对话询问，用的是LibreChat，给个链接
https://github.com/danny-avila/LibreChat
然后这个东西吧，配起来没那么简单，还是 docker compose 的部署方法快捷
那有openrouter的api，这个接入简单。那同时之前还有用Azure gpt-4o的api，用的是Javis，直接接入Azure
Javis偏弱，现在想统一用到LibreChat，接入还真的是一言难尽
来详细说说Azure的配法，背景：Azure是同事在2024年开的，只给了我三个参数
AZURE_OPENAI_API_BASE="https://pppqqq-eus.openai.azure.com/" OPENAI_API_KEY="12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M" AZURE_OPENAI_DEPLOYMENT_NAME="gpt-4o-abc" 然后呢，同事还离职了，然后其它参数就都问不到了
LibreChat呢，文档简直稀烂，而且变动还特别大
LibreChat主要的思路呢，就是在.env中定义变量，然后在librechat.yaml中使用变量，我们就省了，都扔到librechat.yaml中好了
endpoints: azureOpenAI: titleModel: "gpt-4o" plugins: true groups: - group: "azure" apiKey: "12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M" instanceName: "pppqqq-eus" version: "2024-05-01-preview" # 推荐使用新版API，以支持GPT-4o # --- Model-Level Mapping (重点) --- models: # LibreChat显示的名称: 实际Azure部署的名称 gpt-4o: # <--- 这个名称会显示在LibreChat的下拉菜单中 deploymentName: "gpt-4o-abc" # <--- 您的实际Azure部署名称 version: "2024-05-01-preview" # 可覆盖group的version gpt-4-turbo-2024-04-09: # LibreChat显示的名称 deploymentName: "gpt-4o-abc" # 您的实际Azure部署名称 version: "2024-02-15-preview" 上面的配置是问了gemini给出的，看得出来变量AZURE_OPENAI_API_BASE中的xxx.openai.azure.com前面的xxx，就是instanceName
OPENAI_API_KEY就是apiKey
AZURE_OPENAI_DEPLOYMENT_NAME就是deploymentName
模型的gpt-4o还有gpt-4-turbo-2024-04-09都是geimini给出的，version也很重要，不对会报错
然后就可以了'><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-10T09:00:01+08:00"><meta property="article:modified_time" content="2025-12-10T09:00:01+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="LibreChat如何配置接入Azure"><meta name=twitter:description content='Ai的时代已经来临，现在主用的是谷歌的antigravity，然后平时对话询问，用的是LibreChat，给个链接
https://github.com/danny-avila/LibreChat
然后这个东西吧，配起来没那么简单，还是 docker compose 的部署方法快捷
那有openrouter的api，这个接入简单。那同时之前还有用Azure gpt-4o的api，用的是Javis，直接接入Azure
Javis偏弱，现在想统一用到LibreChat，接入还真的是一言难尽
来详细说说Azure的配法，背景：Azure是同事在2024年开的，只给了我三个参数
AZURE_OPENAI_API_BASE="https://pppqqq-eus.openai.azure.com/"
OPENAI_API_KEY="12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M"
AZURE_OPENAI_DEPLOYMENT_NAME="gpt-4o-abc"
然后呢，同事还离职了，然后其它参数就都问不到了
LibreChat呢，文档简直稀烂，而且变动还特别大
LibreChat主要的思路呢，就是在.env中定义变量，然后在librechat.yaml中使用变量，我们就省了，都扔到librechat.yaml中好了
endpoints:
  azureOpenAI:
    titleModel: "gpt-4o"
    plugins: true
    groups:
      - group: "azure"
        apiKey: "12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M"
        instanceName: "pppqqq-eus"
        version: "2024-05-01-preview" # 推荐使用新版API，以支持GPT-4o
        # --- Model-Level Mapping (重点) ---
        models:
          # LibreChat显示的名称: 实际Azure部署的名称
          gpt-4o: # <--- 这个名称会显示在LibreChat的下拉菜单中
            deploymentName: "gpt-4o-abc" # <--- 您的实际Azure部署名称
            version: "2024-05-01-preview" # 可覆盖group的version
          gpt-4-turbo-2024-04-09: # LibreChat显示的名称
            deploymentName: "gpt-4o-abc" # 您的实际Azure部署名称
            version: "2024-02-15-preview"
上面的配置是问了gemini给出的，看得出来变量AZURE_OPENAI_API_BASE中的xxx.openai.azure.com前面的xxx，就是instanceName
OPENAI_API_KEY就是apiKey
AZURE_OPENAI_DEPLOYMENT_NAME就是deploymentName
模型的gpt-4o还有gpt-4-turbo-2024-04-09都是geimini给出的，version也很重要，不对会报错
然后就可以了'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"所有文章","item":"https://rendoumi.com/posts/"},{"@type":"ListItem","position":2,"name":"LibreChat如何配置接入Azure","item":"https://rendoumi.com/posts/20251210-librechat_azure/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LibreChat如何配置接入Azure","name":"LibreChat如何配置接入Azure","description":"Ai的时代已经来临，现在主用的是谷歌的antigravity，然后平时对话询问，用的是LibreChat，给个链接\nhttps://github.com/danny-avila/LibreChat\n然后这个东西吧，配起来没那么简单，还是 docker compose 的部署方法快捷\n那有openrouter的api，这个接入简单。那同时之前还有用Azure gpt-4o的api，用的是Javis，直接接入Azure\nJavis偏弱，现在想统一用到LibreChat，接入还真的是一言难尽\n来详细说说Azure的配法，背景：Azure是同事在2024年开的，只给了我三个参数\nAZURE_OPENAI_API_BASE=\u0026#34;https://pppqqq-eus.openai.azure.com/\u0026#34; OPENAI_API_KEY=\u0026#34;12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M\u0026#34; AZURE_OPENAI_DEPLOYMENT_NAME=\u0026#34;gpt-4o-abc\u0026#34; 然后呢，同事还离职了，然后其它参数就都问不到了\nLibreChat呢，文档简直稀烂，而且变动还特别大\nLibreChat主要的思路呢，就是在.env中定义变量，然后在librechat.yaml中使用变量，我们就省了，都扔到librechat.yaml中好了\nendpoints: azureOpenAI: titleModel: \u0026#34;gpt-4o\u0026#34; plugins: true groups: - group: \u0026#34;azure\u0026#34; apiKey: \u0026#34;12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M\u0026#34; instanceName: \u0026#34;pppqqq-eus\u0026#34; version: \u0026#34;2024-05-01-preview\u0026#34; # 推荐使用新版API，以支持GPT-4o # --- Model-Level Mapping (重点) --- models: # LibreChat显示的名称: 实际Azure部署的名称 gpt-4o: # \u0026lt;--- 这个名称会显示在LibreChat的下拉菜单中 deploymentName: \u0026#34;gpt-4o-abc\u0026#34; # \u0026lt;--- 您的实际Azure部署名称 version: \u0026#34;2024-05-01-preview\u0026#34; # 可覆盖group的version gpt-4-turbo-2024-04-09: # LibreChat显示的名称 deploymentName: \u0026#34;gpt-4o-abc\u0026#34; # 您的实际Azure部署名称 version: \u0026#34;2024-02-15-preview\u0026#34; 上面的配置是问了gemini给出的，看得出来变量AZURE_OPENAI_API_BASE中的xxx.openai.azure.com前面的xxx，就是instanceName\nOPENAI_API_KEY就是apiKey\nAZURE_OPENAI_DEPLOYMENT_NAME就是deploymentName\n模型的gpt-4o还有gpt-4-turbo-2024-04-09都是geimini给出的，version也很重要，不对会报错\n然后就可以了\n","keywords":[],"articleBody":"Ai的时代已经来临，现在主用的是谷歌的antigravity，然后平时对话询问，用的是LibreChat，给个链接\nhttps://github.com/danny-avila/LibreChat\n然后这个东西吧，配起来没那么简单，还是 docker compose 的部署方法快捷\n那有openrouter的api，这个接入简单。那同时之前还有用Azure gpt-4o的api，用的是Javis，直接接入Azure\nJavis偏弱，现在想统一用到LibreChat，接入还真的是一言难尽\n来详细说说Azure的配法，背景：Azure是同事在2024年开的，只给了我三个参数\nAZURE_OPENAI_API_BASE=\"https://pppqqq-eus.openai.azure.com/\" OPENAI_API_KEY=\"12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M\" AZURE_OPENAI_DEPLOYMENT_NAME=\"gpt-4o-abc\" 然后呢，同事还离职了，然后其它参数就都问不到了\nLibreChat呢，文档简直稀烂，而且变动还特别大\nLibreChat主要的思路呢，就是在.env中定义变量，然后在librechat.yaml中使用变量，我们就省了，都扔到librechat.yaml中好了\nendpoints: azureOpenAI: titleModel: \"gpt-4o\" plugins: true groups: - group: \"azure\" apiKey: \"12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M\" instanceName: \"pppqqq-eus\" version: \"2024-05-01-preview\" # 推荐使用新版API，以支持GPT-4o # --- Model-Level Mapping (重点) --- models: # LibreChat显示的名称: 实际Azure部署的名称 gpt-4o: # \u003c--- 这个名称会显示在LibreChat的下拉菜单中 deploymentName: \"gpt-4o-abc\" # \u003c--- 您的实际Azure部署名称 version: \"2024-05-01-preview\" # 可覆盖group的version gpt-4-turbo-2024-04-09: # LibreChat显示的名称 deploymentName: \"gpt-4o-abc\" # 您的实际Azure部署名称 version: \"2024-02-15-preview\" 上面的配置是问了gemini给出的，看得出来变量AZURE_OPENAI_API_BASE中的xxx.openai.azure.com前面的xxx，就是instanceName\nOPENAI_API_KEY就是apiKey\nAZURE_OPENAI_DEPLOYMENT_NAME就是deploymentName\n模型的gpt-4o还有gpt-4-turbo-2024-04-09都是geimini给出的，version也很重要，不对会报错\n然后就可以了\n不得不说，还是openroute的模型多啊，可惜就是太费钱了。Token哗哗飞，动辄都是65535Token\n","wordCount":"72","inLanguage":"zh","datePublished":"2025-12-10T09:00:01+08:00","dateModified":"2025-12-10T09:00:01+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://rendoumi.com/posts/20251210-librechat_azure/"},"publisher":{"@type":"Organization","name":"八戒的技术博客","logo":{"@type":"ImageObject","url":"https://rendoumi.com/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://rendoumi.com/ accesskey=h title="八戒的技术博客 (Alt + H)">八戒的技术博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rendoumi.com/ title=首页><span>首页</span></a></li><li><a href=https://rendoumi.com/posts/ title=文章><span>文章</span></a></li><li><a href=https://rendoumi.com/archives/ title=归档><span>归档</span></a></li><li><a href=https://blog.rendoumi.com title=生活><span>生活</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://rendoumi.com/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">LibreChat如何配置接入Azure
<span class=entry-hint title=Draft><svg height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2025-12-10 09:00:01 +0800 CST'>2025年12月10日</span></div></header><div class=post-content><p>Ai的时代已经来临，现在主用的是谷歌的antigravity，然后平时对话询问，用的是LibreChat，给个链接</p><p><a href=https://github.com/danny-avila/LibreChat>https://github.com/danny-avila/LibreChat</a></p><p>然后这个东西吧，配起来没那么简单，还是 docker compose 的部署方法快捷</p><p>那有openrouter的api，这个接入简单。那同时之前还有用Azure gpt-4o的api，用的是Javis，直接接入Azure</p><p>Javis偏弱，现在想统一用到LibreChat，接入还真的是一言难尽</p><p>来详细说说Azure的配法，背景：Azure是同事在2024年开的，只给了我三个参数</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>AZURE_OPENAI_API_BASE</span><span class=o>=</span><span class=s2>&#34;https://pppqqq-eus.openai.azure.com/&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>OPENAI_API_KEY</span><span class=o>=</span><span class=s2>&#34;12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M&#34;</span>
</span></span><span class=line><span class=cl><span class=nv>AZURE_OPENAI_DEPLOYMENT_NAME</span><span class=o>=</span><span class=s2>&#34;gpt-4o-abc&#34;</span>
</span></span></code></pre></div><p>然后呢，同事还离职了，然后其它参数就都问不到了</p><p>LibreChat呢，文档简直稀烂，而且变动还特别大</p><p>LibreChat主要的思路呢，就是在.env中定义变量，然后在librechat.yaml中使用变量，我们就省了，都扔到librechat.yaml中好了</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>endpoints:
</span></span><span class=line><span class=cl>  azureOpenAI:
</span></span><span class=line><span class=cl>    titleModel: <span class=s2>&#34;gpt-4o&#34;</span>
</span></span><span class=line><span class=cl>    plugins: <span class=nb>true</span>
</span></span><span class=line><span class=cl>    groups:
</span></span><span class=line><span class=cl>      - group: <span class=s2>&#34;azure&#34;</span>
</span></span><span class=line><span class=cl>        apiKey: <span class=s2>&#34;12xxxaaabbbccccccccccccgggggggggggggggggggggggggggCOGuy6M&#34;</span>
</span></span><span class=line><span class=cl>        instanceName: <span class=s2>&#34;pppqqq-eus&#34;</span>
</span></span><span class=line><span class=cl>        version: <span class=s2>&#34;2024-05-01-preview&#34;</span> <span class=c1># 推荐使用新版API，以支持GPT-4o</span>
</span></span><span class=line><span class=cl>        <span class=c1># --- Model-Level Mapping (重点) ---</span>
</span></span><span class=line><span class=cl>        models:
</span></span><span class=line><span class=cl>          <span class=c1># LibreChat显示的名称: 实际Azure部署的名称</span>
</span></span><span class=line><span class=cl>          gpt-4o: <span class=c1># &lt;--- 这个名称会显示在LibreChat的下拉菜单中</span>
</span></span><span class=line><span class=cl>            deploymentName: <span class=s2>&#34;gpt-4o-abc&#34;</span> <span class=c1># &lt;--- 您的实际Azure部署名称</span>
</span></span><span class=line><span class=cl>            version: <span class=s2>&#34;2024-05-01-preview&#34;</span> <span class=c1># 可覆盖group的version</span>
</span></span><span class=line><span class=cl>          gpt-4-turbo-2024-04-09: <span class=c1># LibreChat显示的名称</span>
</span></span><span class=line><span class=cl>            deploymentName: <span class=s2>&#34;gpt-4o-abc&#34;</span> <span class=c1># 您的实际Azure部署名称</span>
</span></span><span class=line><span class=cl>            version: <span class=s2>&#34;2024-02-15-preview&#34;</span>
</span></span></code></pre></div><p>上面的配置是问了gemini给出的，看得出来变量AZURE_OPENAI_API_BASE中的xxx.openai.azure.com前面的xxx，就是instanceName</p><p>OPENAI_API_KEY就是apiKey</p><p>AZURE_OPENAI_DEPLOYMENT_NAME就是deploymentName</p><p>模型的gpt-4o还有gpt-4-turbo-2024-04-09都是geimini给出的，version也很重要，不对会报错</p><p>然后就可以了</p><p><img alt=image-20251210103215838 loading=lazy src=/posts/20251210-librechat_azure/image-20251210103215838.png></p><p>不得不说，还是openroute的模型多啊，可惜就是太费钱了。Token哗哗飞，动辄都是65535Token</p><p><img alt=image-20251210103251472 loading=lazy src=/posts/20251210-librechat_azure/image-20251210103251472.png></p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>Copyright © 2020-2025 Zhang Ranrui. All Rights Reserved.</span><br>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>