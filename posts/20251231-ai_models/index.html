<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3988508441804851" crossorigin=anonymous></script><title>整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站) | 八戒的技术博客</title>
<meta name=keywords content><meta name=description content="整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)-转自Linux.do
​
现在AI的使用场景越来越多，公益站有时也不稳定，给大家整理一些能提供相对长期稳定大模型api的厂商和平台，作为备用或测试。
这里主要收集文本大模型，图片视频生成相关的大模型没有专门做整理。
tldr

国内大模型平台太卷了，免费额度真的很多，如果没有特殊需求，国内的api就够用了。
主力模型推荐: 阿里iflow, 字节火山引擎, 阿里 modelscope 魔搭社区。
免费vibe coding推荐: 腾讯codebuddy,  快手codeflicker, 阿里通义灵码/qwen-code

非稳定渠道
一些平台会不定期推出吸引用户的免费活动，适合用来测试和临时应急。下面列出一些，过期了的就评论下提醒我删掉。

AI Ping

20251226 限时免费: glm-4.7, minimax-m2.1, deepseek-v3.2, douban-seeddream文生图




模型限制相关说明

rpm(Requests per minute): 每分钟请求次数
rpd(Requests per day): 每天请求次数
tpm(Tokens per minute): 每分钟输入输出的token数
tpd(Tokens per day): 每天输入输出的token数

Vibe Coding 免费代码工具

国内的 ai coding 太卷了，各家都提供了很大的免费额度

腾讯云代码助手 CodeBuddy, 独立IDE

目前(20251222)免费使用 glm-4.6, deepseek-v3.1-terminus, huyuan-2.0

20251223: 免费提供最新的 glm-4.7



快手 CodeFlicker , 独立IDE

目前(20251222)免费使用 kimi-k2-0905, kat-coder-pro

阿里 通义灵码 , 独立IDE

免费不限量使用 千问系列模型，但不可更换使用其他模型

阿里 qwen-code, cli命令行


free tier"><meta name=author content><link rel=canonical href=https://rendoumi.com/posts/20251231-ai_models/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5d8a858b4ad07d913988e10d3c3dbc8c171f45316a396de8a60d67f44840812d.css integrity="sha256-XYqFi0rQfZE5iOENPD28jBcfRTFqOW3opg1n9EhAgS0=" rel="preload stylesheet" as=style><link rel=icon href=https://rendoumi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rendoumi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rendoumi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://rendoumi.com/apple-touch-icon.png><link rel=mask-icon href=https://rendoumi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://rendoumi.com/posts/20251231-ai_models/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rendoumi.com/posts/20251231-ai_models/"><meta property="og:site_name" content="八戒的技术博客"><meta property="og:title" content="整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)"><meta property="og:description" content="整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)-转自Linux.do ​
现在AI的使用场景越来越多，公益站有时也不稳定，给大家整理一些能提供相对长期稳定大模型api的厂商和平台，作为备用或测试。
这里主要收集文本大模型，图片视频生成相关的大模型没有专门做整理。
tldr
国内大模型平台太卷了，免费额度真的很多，如果没有特殊需求，国内的api就够用了。 主力模型推荐: 阿里iflow, 字节火山引擎, 阿里 modelscope 魔搭社区。 免费vibe coding推荐: 腾讯codebuddy, 快手codeflicker, 阿里通义灵码/qwen-code 非稳定渠道 一些平台会不定期推出吸引用户的免费活动，适合用来测试和临时应急。下面列出一些，过期了的就评论下提醒我删掉。
AI Ping 20251226 限时免费: glm-4.7, minimax-m2.1, deepseek-v3.2, douban-seeddream文生图 模型限制相关说明
rpm(Requests per minute): 每分钟请求次数 rpd(Requests per day): 每天请求次数 tpm(Tokens per minute): 每分钟输入输出的token数 tpd(Tokens per day): 每天输入输出的token数 Vibe Coding 免费代码工具 国内的 ai coding 太卷了，各家都提供了很大的免费额度 腾讯云代码助手 CodeBuddy, 独立IDE 目前(20251222)免费使用 glm-4.6, deepseek-v3.1-terminus, huyuan-2.0 20251223: 免费提供最新的 glm-4.7 快手 CodeFlicker , 独立IDE 目前(20251222)免费使用 kimi-k2-0905, kat-coder-pro 阿里 通义灵码 , 独立IDE 免费不限量使用 千问系列模型，但不可更换使用其他模型 阿里 qwen-code, cli命令行 free tier"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-31T09:30:01+08:00"><meta property="article:modified_time" content="2025-12-31T09:30:01+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)"><meta name=twitter:description content="整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)-转自Linux.do
​
现在AI的使用场景越来越多，公益站有时也不稳定，给大家整理一些能提供相对长期稳定大模型api的厂商和平台，作为备用或测试。
这里主要收集文本大模型，图片视频生成相关的大模型没有专门做整理。
tldr

国内大模型平台太卷了，免费额度真的很多，如果没有特殊需求，国内的api就够用了。
主力模型推荐: 阿里iflow, 字节火山引擎, 阿里 modelscope 魔搭社区。
免费vibe coding推荐: 腾讯codebuddy,  快手codeflicker, 阿里通义灵码/qwen-code

非稳定渠道
一些平台会不定期推出吸引用户的免费活动，适合用来测试和临时应急。下面列出一些，过期了的就评论下提醒我删掉。

AI Ping

20251226 限时免费: glm-4.7, minimax-m2.1, deepseek-v3.2, douban-seeddream文生图




模型限制相关说明

rpm(Requests per minute): 每分钟请求次数
rpd(Requests per day): 每天请求次数
tpm(Tokens per minute): 每分钟输入输出的token数
tpd(Tokens per day): 每天输入输出的token数

Vibe Coding 免费代码工具

国内的 ai coding 太卷了，各家都提供了很大的免费额度

腾讯云代码助手 CodeBuddy, 独立IDE

目前(20251222)免费使用 glm-4.6, deepseek-v3.1-terminus, huyuan-2.0

20251223: 免费提供最新的 glm-4.7



快手 CodeFlicker , 独立IDE

目前(20251222)免费使用 kimi-k2-0905, kat-coder-pro

阿里 通义灵码 , 独立IDE

免费不限量使用 千问系列模型，但不可更换使用其他模型

阿里 qwen-code, cli命令行


free tier"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"所有文章","item":"https://rendoumi.com/posts/"},{"@type":"ListItem","position":2,"name":"整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)","item":"https://rendoumi.com/posts/20251231-ai_models/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)","name":"整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)","description":"整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)-转自Linux.do ​\n现在AI的使用场景越来越多，公益站有时也不稳定，给大家整理一些能提供相对长期稳定大模型api的厂商和平台，作为备用或测试。\n这里主要收集文本大模型，图片视频生成相关的大模型没有专门做整理。\ntldr\n国内大模型平台太卷了，免费额度真的很多，如果没有特殊需求，国内的api就够用了。 主力模型推荐: 阿里iflow, 字节火山引擎, 阿里 modelscope 魔搭社区。 免费vibe coding推荐: 腾讯codebuddy, 快手codeflicker, 阿里通义灵码/qwen-code 非稳定渠道 一些平台会不定期推出吸引用户的免费活动，适合用来测试和临时应急。下面列出一些，过期了的就评论下提醒我删掉。\nAI Ping 20251226 限时免费: glm-4.7, minimax-m2.1, deepseek-v3.2, douban-seeddream文生图 模型限制相关说明\nrpm(Requests per minute): 每分钟请求次数 rpd(Requests per day): 每天请求次数 tpm(Tokens per minute): 每分钟输入输出的token数 tpd(Tokens per day): 每天输入输出的token数 Vibe Coding 免费代码工具 国内的 ai coding 太卷了，各家都提供了很大的免费额度 腾讯云代码助手 CodeBuddy, 独立IDE 目前(20251222)免费使用 glm-4.6, deepseek-v3.1-terminus, huyuan-2.0 20251223: 免费提供最新的 glm-4.7 快手 CodeFlicker , 独立IDE 目前(20251222)免费使用 kimi-k2-0905, kat-coder-pro 阿里 通义灵码 , 独立IDE 免费不限量使用 千问系列模型，但不可更换使用其他模型 阿里 qwen-code, cli命令行 free tier\n","keywords":[],"articleBody":"整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)-转自Linux.do ​\n现在AI的使用场景越来越多，公益站有时也不稳定，给大家整理一些能提供相对长期稳定大模型api的厂商和平台，作为备用或测试。\n这里主要收集文本大模型，图片视频生成相关的大模型没有专门做整理。\ntldr\n国内大模型平台太卷了，免费额度真的很多，如果没有特殊需求，国内的api就够用了。 主力模型推荐: 阿里iflow, 字节火山引擎, 阿里 modelscope 魔搭社区。 免费vibe coding推荐: 腾讯codebuddy, 快手codeflicker, 阿里通义灵码/qwen-code 非稳定渠道 一些平台会不定期推出吸引用户的免费活动，适合用来测试和临时应急。下面列出一些，过期了的就评论下提醒我删掉。\nAI Ping 20251226 限时免费: glm-4.7, minimax-m2.1, deepseek-v3.2, douban-seeddream文生图 模型限制相关说明\nrpm(Requests per minute): 每分钟请求次数 rpd(Requests per day): 每天请求次数 tpm(Tokens per minute): 每分钟输入输出的token数 tpd(Tokens per day): 每天输入输出的token数 Vibe Coding 免费代码工具 国内的 ai coding 太卷了，各家都提供了很大的免费额度 腾讯云代码助手 CodeBuddy, 独立IDE 目前(20251222)免费使用 glm-4.6, deepseek-v3.1-terminus, huyuan-2.0 20251223: 免费提供最新的 glm-4.7 快手 CodeFlicker , 独立IDE 目前(20251222)免费使用 kimi-k2-0905, kat-coder-pro 阿里 通义灵码 , 独立IDE 免费不限量使用 千问系列模型，但不可更换使用其他模型 阿里 qwen-code, cli命令行 free tier\nOpenAI-compatible API, or sign in with Qwen OAuth to get 2,000 free requests/day. rpm 每天 2000 次，免费额度很大 Cline, vscode扩展 / cli命令行 提供多种使用方式，包括vscode里的扩展、独立的cli vscode的模型配置界面长期提供免费模型 20251223免费: minimax-m2, devstral-2512, grok-code-fast, kat-coder-pro Roo Code, vscode扩展 / Cloud Agents 提供多种使用方式，包括vscode里的扩展、云端编程 vscode的模型配置界面长期提供免费模型 Roo Code Cloud Models 20251223免费: MiniMax-M2, Grok Code Fast 1 Kilo Code, vscode扩展 / cli命令行 提供多种使用方式，包括vscode里的扩展、独立的cli vscode的模型配置界面长期提供免费模型 Models 20251223免费: minimax-m2, devstral-2512, kat-coder-pro OpenCode, cli命令行 最近也提供了OpenCode Desktop的使用方式，长期提供免费模型 Zen Models 20251223免费: glm-4.7, Grok Code Fast 1, Big Pickle coding 工具说明 厂商定制的独立IDE一般都不支持使用自己的大模型api/url， 如腾讯CodeBuddy/阿里灵码 cline/roo-code/kilo-code 提供了ui界面可以选择输入自己的模型api/url，使用方便，换模型也方便 open-code/claude-code/codex/qwen-code 这类命令行工具都可以使用自定义模型api/url， 但要自己搜索配置方法折腾下 国内厂商或平台 阿里心流 iflow S级推荐:\n心流开放平台\niflow-cli 是可以免费使用的 vibe coding 工具, 对标 claude code 目前我所知的免费额度最大的平台，不限量，速度也很快\n主要提供的模型: 阿里千问系列模型较多， 还有 Kimi-K2-Instruct-0905, GLM-4.6, DeepSeek-V3.2-Exp, Qwen3-Coder-Plus\n限流\n每个用户最多只能 同时发起一个 请求，超出限制的请求会返回429错误码。 iflow社区反馈 api 可用的模型很久没更新了，官方似乎准备将更多资源投入iflow-cli,\niflow-cli支持最新的 glm-4.7 / minimax-m2.1 通过开源转换工具如 CLIProxyAPI 可以将 iflow-cli 的免费模型转换成类似公益站的api， 需要折腾一下，不过渠道真的很稳 字节火山方舟大模型 目前 每个模型 每天免费 250w token， 速度很快，体验很好，但单模型token不够用，经常切换模型我觉得麻烦 主要提供的模型: 豆包系列模型较多，最新的deepseek-v3.2, Kimi-K2-Instruct-0905 还提供文生图相关模型 免费推理额度 rpm/tpm各模型不同，一般rpm为1000～10000， tpm为500w 阿里 modelscope 魔搭社区 每天允许进行 总数为 2000 次 的API-Inference调用，其中每单个模型不超过 500 次，具体每个模型的限制可能随时动态调整。 我不太喜欢阿里的modelscope， 受欢迎的模型总是开放一段时间就下架，但提供的免费额度很稳定，千问系列模型很稳定 还提供文生图相关模型 限制 在每个模型每天不超过 500 次调用的基础上，平台可能对于部分模型再进行单独的限制，例如，deepseek-ai/DeepSeek-R1-0528，deepseek-ai/DeepSeek-V3.1等规格较大模型，当前限制 单模型每天200次 调用额度。 -在上述调用次数限制的基础上，不同模型允许的调用并发，会根据平台的压力进行动态的速率限制调整，原则上以保障开发者单并发正常使用为目标 快手 KAT-Coder 系列模型 KAT-Coder-Pro V1 和 KAT-Coder-Air 目前都提供免费使用，其中 KAT-Coder-Air 长期提供免费使用 我经常拿来做测试，速度很快，对结果要求不高可以试试 KAT-Coder-Air V1 模型免费使用规则 高峰时段: 08:00-02:00（次日）, 每6小时内您将可以发起 120次 对话请求。 非高峰时段: 02:00-08:00, 每6小时内您将可以发起 200次 对话请求 智谱 glm flash 系列模型 智谱AI开放平台 福利专区 少数的模型厂商自己提供免费模型api，长期稳定，免费的都是小模型，但种类比较全 速度很快，但效果不好，适合用来测试 模型包括: GLM-4-Flash-250414, GLM-4.1V-Thinking-Flash, Cogview-3-Flash(文生图), CogVideoX-Flash(视频生成) 速率限制 限制的维度是请求 并发 数量（在途请求任务数量）， GLM-4-Flash为200, GLM-4V-Flash为10 硅基流动 SiliconFlow 长期稳定提供免费的小模型，大多7b/8b/9b的小模型，速度快 不提供32b以上的免费模型，小模型质量较差，我平时用的少 Rate Limits 大多都是 tpm-50k 国内 Others 上面都是我用的比较多的，下面是一些其他免费模型，大家也可以补充 美团 LongCat 系列模型 LongCat API开放平台 每个账号每天自动获得 500,000 Tokens 免费额度 单次请求限制 输出文本：最大8K Tokens， 当触发限流时，API将返回HTTP状态码429 特别提及: 七牛 AI 大模型推理服务 这是我所知的国内仅有的大模型平台，官方能提供 OpenAI/Claude/Gemini 模型，不知道是不是 2API 的渠道 官方提供300w免费token, 有效期一年， 速度很快，强烈推荐，能用各种模型 AI 大模型推理服务 - 七牛云 国外厂商或平台 显卡一哥英伟达老黄的福利 - Nvidia NIM API 我觉得比openrouter更好用，似乎免费不限量 提供各种模型， 包括国外的模型: deepseek-v3.2, qwen3-coder-480b, kimi-k2-thinking, minimax-m2, mistral-large, devstral 不支持: glm-4.6/4.7, minimax-m2.1 还支持部分文生图模型, FLUX.1-dev免费 25 requests, 可以试试 Try NVIDIA NIM APIs 限制 rpm: 40 Cerebras Inference 我体验过的速度最快的大模型平台，速度可达 220+ token/s, S级推荐 提供的免费模型较少，经常更换，现在包括: glm-4.6, qwen-3-235b-a22b-instruct-2507, gpt-oss-120b, … Rate Limits RPM: 10~30 TPD: 1M , 每天 100w token 有点不够用，但爽就完事了 OpenRouter 长期稳定，模型丰富 API Rate Limits 不充钱的用户每天 50 rpd, 充了10刀的用户每天 1000 rpd 很多公益站都用了 OpenRouter 的渠道 Mistral 欧洲主流模型厂商，提供长期稳定的模型api 我试过在官方聊天网站 Le Chat 体验的效果很差，远不如国内的模型， 我还试过在本地用 Ollama / LM Studio 跑 mistral/devstral 系列的模型也远不如国内的qwen3-32b内的模型，但reddit论坛很多人都在吹mistral系列的模型，我觉得就是老欧人的自嗨 Rate Limits \u0026 Usage tiers 免费额度非常大， Tokens per Minute 500,000 Tokens per Month 1,000,000,000，大约每天 rpd 是 3300w Codestral mistral系列专注于coding的模型似乎有额外的免费额度，但我没用过，因为coding模型竞争太激烈了，有其他选择 国外 Others groq 免费模型种类多，但大模型不多，大多是小模型， 免费额度较少 免费大模型包括: kimi-k2-instruct-0905, gpt-oss-120b, llama-4-maverick-17b-128e Rate Limits rpm - 10~60 tokens per day 是 100K~500K, 每天的token太少了，不够用 Poe poe 既不是模型研发厂商，也不是聚合平台，主要业务是方便用户通过ui创建chat-bot和自动化任务bot，也提供了模型api供用户使用\n免费用户每天发放 3000 points, 仅当日有效\nPoe FAQs 官方文档提到了支持 claude-code, cline, cursor, continue\n佬友 tips: 用之前建议一个个模型按费率和收费标准选一下，像 Grok-4.1-Fast 、Gemini Flash 系列、GPT-5-mini/GPT-5-nano 都不怎么耗积分\n我个人不推荐使用这家的api， 因为不支持结构化输出，这是ai非聊天类工具大多需要的基础功能\nStructured outputs are not supported The strict parameter for function calling is ignored, which means the tool use JSON is not guaranteed to follow the supplied schema. OpenAI Compatible API Chutes 目前限时免费的模型有4个: GLM 4.5 Air, Gpt Oss 20b, Gemma 3 4b, Tongyi DeepResearch 30B 免费的模型参数不够大，不如其他平台 Chutes Free Models 目前测试注册就可以用，不需要充钱，只写了限时免费，没找到请求速度限制说明 不推荐使用这个平台，因为免费规则经常调整，在25年7月需要充5刀了才给200rpd免费额度 ZenMux 目前提供了4个免费模型: gemini-3-flash-preview-free, xiaomi/mimo-v2-flash, kuaishou/kat-coder-pro-v1, z-ai/glm-4.6v-flash Free Models - ZenMux 测试时gemini-3-flash返回异常429, xiaomi-mino能用但速度一般 这个平台我看25年8月才开始运营，是不是长期稳定还要让子弹飞一会儿，以后会关注更新 Huggingface 国外平台我用的少，大家可以补充一些反馈和其他平台 其他 这么多免费大模型api，不知道有没有什么好的统一管理的方法 ","wordCount":"526","inLanguage":"zh","datePublished":"2025-12-31T09:30:01+08:00","dateModified":"2025-12-31T09:30:01+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://rendoumi.com/posts/20251231-ai_models/"},"publisher":{"@type":"Organization","name":"八戒的技术博客","logo":{"@type":"ImageObject","url":"https://rendoumi.com/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://rendoumi.com/ accesskey=h title="八戒的技术博客 (Alt + H)">八戒的技术博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rendoumi.com/ title=首页><span>首页</span></a></li><li><a href=https://rendoumi.com/posts/ title=文章><span>文章</span></a></li><li><a href=https://rendoumi.com/archives/ title=归档><span>归档</span></a></li><li><a href=https://blog.rendoumi.com title=生活><span>生活</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://rendoumi.com/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)
<span class=entry-hint title=Draft><svg height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2025-12-31 09:30:01 +0800 CST'>2025年12月31日</span></div></header><div class=post-content><h1 id=整理下ai大模型厂商和平台能长期稳定提供免费额度的api-非公益站-转自linuxdo>整理下AI大模型厂商和平台，能长期稳定提供免费额度的API (非公益站)-转自Linux.do<a hidden class=anchor aria-hidden=true href=#整理下ai大模型厂商和平台能长期稳定提供免费额度的api-非公益站-转自linuxdo>#</a></h1><p>​</p><p>现在AI的使用场景越来越多，公益站有时也不稳定，给大家整理一些能提供相对长期稳定大模型api的厂商和平台，作为备用或测试。</p><p>这里主要收集文本大模型，图片视频生成相关的大模型没有专门做整理。</p><p><strong>tldr</strong></p><ul><li>国内大模型平台太卷了，免费额度真的很多，如果没有特殊需求，国内的api就够用了。</li><li>主力模型推荐: 阿里iflow, 字节火山引擎, 阿里 modelscope 魔搭社区。</li><li>免费vibe coding推荐: 腾讯codebuddy, 快手codeflicker, 阿里通义灵码/qwen-code</li></ul><h2 id=非稳定渠道>非稳定渠道<a hidden class=anchor aria-hidden=true href=#非稳定渠道>#</a></h2><p>一些平台会不定期推出吸引用户的免费活动，适合用来测试和临时应急。下面列出一些，过期了的就评论下提醒我删掉。</p><ul><li>AI Ping<ul><li>20251226 限时免费: <strong>glm-4.7</strong>, <strong>minimax-m2.1</strong>, deepseek-v3.2, douban-seeddream文生图</li></ul></li></ul><blockquote><p>模型限制相关说明</p><ul><li>rpm(Requests per minute): 每分钟请求次数</li><li>rpd(Requests per day): 每天请求次数</li><li>tpm(Tokens per minute): 每分钟输入输出的token数</li><li>tpd(Tokens per day): 每天输入输出的token数</li></ul></blockquote><h2 id=vibe-coding-免费代码工具>Vibe Coding 免费代码工具<a hidden class=anchor aria-hidden=true href=#vibe-coding-免费代码工具>#</a></h2><ul><li>国内的 ai coding 太卷了，各家都提供了很大的免费额度</li></ul><h3 id=腾讯云代码助手-codebuddy-独立ide><a href=https://copilot.tencent.com/ide/>腾讯云代码助手 CodeBuddy</a>, 独立IDE<a hidden class=anchor aria-hidden=true href=#腾讯云代码助手-codebuddy-独立ide>#</a></h3><ul><li>目前(20251222)免费使用 glm-4.6, deepseek-v3.1-terminus, huyuan-2.0<ul><li>20251223: 免费提供最新的 <strong>glm-4.7</strong></li></ul></li></ul><h3 id=快手-codeflicker--独立ide>快手 <a href=https://www.codeflicker.ai/>CodeFlicker </a>, 独立IDE<a hidden class=anchor aria-hidden=true href=#快手-codeflicker--独立ide>#</a></h3><ul><li>目前(20251222)免费使用 kimi-k2-0905, kat-coder-pro</li></ul><h3 id=阿里-通义灵码--独立ide>阿里 <a href=https://lingma.aliyun.com/>通义灵码 </a>, 独立IDE<a hidden class=anchor aria-hidden=true href=#阿里-通义灵码--独立ide>#</a></h3><ul><li>免费不限量使用 千问系列模型，但不可更换使用其他模型</li></ul><h3 id=阿里-qwen-code-cli命令行>阿里 <a href=https://github.com/QwenLM/qwen-code>qwen-code</a>, cli命令行<a hidden class=anchor aria-hidden=true href=#阿里-qwen-code-cli命令行>#</a></h3><ul><li><p>free tier</p><ul><li>OpenAI-compatible API, or sign in with Qwen OAuth to get 2,000 free requests/day.</li></ul><ul><li>rpm 每天 2000 次，免费额度很大</li></ul></li></ul><h3 id=cline-vscode扩展--cli命令行><a href=https://cline.bot/pricing>Cline</a>, vscode扩展 / cli命令行<a hidden class=anchor aria-hidden=true href=#cline-vscode扩展--cli命令行>#</a></h3><ul><li>提供多种使用方式，包括vscode里的扩展、独立的cli</li><li>vscode的模型配置界面长期提供免费模型<ul><li>20251223免费: minimax-m2, devstral-2512, grok-code-fast, kat-coder-pro</li></ul></li></ul><h3 id=roo-code-vscode扩展--cloud-agents><a href=https://roocode.com/pricing>Roo Code</a>, vscode扩展 / Cloud Agents<a hidden class=anchor aria-hidden=true href=#roo-code-vscode扩展--cloud-agents>#</a></h3><ul><li>提供多种使用方式，包括vscode里的扩展、云端编程</li><li>vscode的模型配置界面长期提供免费模型<ul><li><a href=https://app.roocode.com/models>Roo Code Cloud Models</a></li><li>20251223免费: MiniMax-M2, Grok Code Fast 1</li></ul></li></ul><h3 id=kilo-code-vscode扩展--cli命令行><a href=https://kilo.ai>Kilo Code</a>, vscode扩展 / cli命令行<a hidden class=anchor aria-hidden=true href=#kilo-code-vscode扩展--cli命令行>#</a></h3><ul><li>提供多种使用方式，包括vscode里的扩展、独立的cli</li><li>vscode的模型配置界面长期提供免费模型<ul><li><a href=https://kilo.ai/models>Models</a></li><li>20251223免费: minimax-m2, devstral-2512, kat-coder-pro</li></ul></li></ul><h3 id=opencode-cli命令行><a href=https://opencode.ai>OpenCode</a>, cli命令行<a hidden class=anchor aria-hidden=true href=#opencode-cli命令行>#</a></h3><ul><li>最近也提供了OpenCode Desktop的使用方式，长期提供免费模型<ul><li><a href=https://opencode.ai/docs/zen#models>Zen Models</a></li><li>20251223免费: <strong>glm-4.7</strong>, Grok Code Fast 1, Big Pickle</li></ul></li></ul><h3 id=coding-工具说明>coding 工具说明<a hidden class=anchor aria-hidden=true href=#coding-工具说明>#</a></h3><blockquote><ul><li>厂商定制的独立IDE一般都不支持使用自己的大模型api/url， 如腾讯CodeBuddy/阿里灵码</li><li>cline/roo-code/kilo-code 提供了ui界面可以选择输入自己的模型api/url，使用方便，换模型也方便</li><li>open-code/claude-code/codex/qwen-code 这类命令行工具都可以使用自定义模型api/url， 但要自己搜索配置方法折腾下</li></ul></blockquote><h2 id=国内厂商或平台>国内厂商或平台<a hidden class=anchor aria-hidden=true href=#国内厂商或平台>#</a></h2><h3 id=阿里心流-iflow>阿里心流 iflow<a hidden class=anchor aria-hidden=true href=#阿里心流-iflow>#</a></h3><ul><li><p>S级推荐:</p><p>心流开放平台</p><ul><li>iflow-cli 是可以免费使用的 vibe coding 工具, 对标 claude code</li></ul></li><li><p>目前我所知的免费额度最大的平台，不限量，速度也很快</p></li><li><p>主要提供的模型: 阿里千问系列模型较多， 还有 Kimi-K2-Instruct-0905, GLM-4.6, DeepSeek-V3.2-Exp, Qwen3-Coder-Plus</p></li><li><p>限流</p><ul><li>每个用户最多只能 <strong>同时发起一个</strong> 请求，超出限制的请求会返回429错误码。</li></ul></li><li><p>iflow社区反馈 api 可用的模型很久没更新了，官方似乎准备将更多资源投入iflow-cli,</p><ul><li>iflow-cli支持最新的 <strong>glm-4.7 / minimax-m2.1</strong></li><li>通过开源转换工具如 <a href=https://github.com/router-for-me/CLIProxyAPI>CLIProxyAPI</a> 可以将 iflow-cli 的免费模型转换成类似公益站的api， 需要折腾一下，不过渠道真的很稳</li></ul></li></ul><h3 id=字节火山方舟大模型>字节火山方舟大模型<a hidden class=anchor aria-hidden=true href=#字节火山方舟大模型>#</a></h3><ul><li>目前 <strong>每个模型</strong> 每天免费 <strong>250w</strong> token， 速度很快，体验很好，但单模型token不够用，经常切换模型我觉得麻烦</li><li>主要提供的模型: 豆包系列模型较多，最新的deepseek-v3.2, Kimi-K2-Instruct-0905</li><li>还提供文生图相关模型</li><li>免费推理额度<ul><li>rpm/tpm各模型不同，一般rpm为1000～10000， tpm为500w</li></ul></li></ul><h3 id=阿里-modelscope-魔搭社区>阿里 modelscope 魔搭社区<a hidden class=anchor aria-hidden=true href=#阿里-modelscope-魔搭社区>#</a></h3><ul><li>每天允许进行 <strong>总数为 2000 次</strong> 的API-Inference调用，其中每<strong>单个模型不超过 500 次</strong>，具体每个模型的限制可能随时动态调整。</li><li>我不太喜欢阿里的modelscope， <strong>受欢迎的模型总是开放一段时间就下架</strong>，但提供的免费额度很稳定，千问系列模型很稳定</li><li>还提供文生图相关模型</li><li>限制<ul><li>在每个模型每天不超过 500 次调用的基础上，平台可能对于部分模型再进行单独的限制，例如，deepseek-ai/DeepSeek-R1-0528，deepseek-ai/DeepSeek-V3.1等规格较大模型，当前限制 <strong>单模型每天200次</strong> 调用额度。
-在上述调用次数限制的基础上，不同模型允许的调用并发，会根据平台的压力进行动态的速率限制调整，原则上以保障开发者单并发正常使用为目标</li></ul></li></ul><h3 id=快手-kat-coder-系列模型>快手 KAT-Coder 系列模型<a hidden class=anchor aria-hidden=true href=#快手-kat-coder-系列模型>#</a></h3><ul><li>KAT-Coder-Pro V1 和 KAT-Coder-Air 目前都提供免费使用，其中 KAT-Coder-Air 长期提供免费使用</li><li>我经常拿来做测试，速度很快，对结果要求不高可以试试</li><li>KAT-Coder-Air V1 模型免费使用规则<ul><li>高峰时段: 08:00-02:00（次日）, <strong>每6小时</strong>内您将可以发起 <strong>120次</strong> 对话请求。</li><li>非高峰时段: 02:00-08:00, <strong>每6小时</strong>内您将可以发起 <strong>200次</strong> 对话请求</li></ul></li></ul><h3 id=智谱-glm-flash-系列模型>智谱 glm flash 系列模型<a hidden class=anchor aria-hidden=true href=#智谱-glm-flash-系列模型>#</a></h3><ul><li><a href=https://bigmodel.cn/dev/activities/free/glm-4-flash>智谱AI开放平台 福利专区</a></li><li>少数的模型厂商自己提供免费模型api，长期稳定，免费的都是小模型，但种类比较全</li><li>速度很快，但效果不好，适合用来测试</li><li>模型包括: GLM-4-Flash-250414, GLM-4.1V-Thinking-Flash, Cogview-3-Flash(文生图), CogVideoX-Flash(视频生成)</li><li>速率限制<ul><li>限制的维度是请求 <strong>并发</strong> 数量（在途请求任务数量）， GLM-4-Flash为200, GLM-4V-Flash为10</li></ul></li></ul><h3 id=硅基流动-siliconflow>硅基流动 SiliconFlow<a hidden class=anchor aria-hidden=true href=#硅基流动-siliconflow>#</a></h3><ul><li>长期稳定提供免费的小模型，大多7b/8b/9b的小模型，速度快</li><li>不提供32b以上的免费模型，小模型质量较差，我平时用的少</li><li>Rate Limits<ul><li>大多都是 tpm-50k</li></ul></li></ul><h3 id=国内-others>国内 Others<a hidden class=anchor aria-hidden=true href=#国内-others>#</a></h3><ul><li>上面都是我用的比较多的，下面是一些其他免费模型，大家也可以补充</li><li><strong>美团 LongCat 系列模型</strong><ul><li><a href=https://longcat.chat/platform/docs/zh/>LongCat API开放平台</a></li><li>每个账号每天自动获得 <strong>500,000 Tokens</strong> 免费额度</li><li>单次请求限制 输出文本：最大8K Tokens， 当触发限流时，API将返回HTTP状态码429</li></ul></li><li><strong>特别提及:</strong> <strong>七牛 AI 大模型推理服务</strong><ul><li>这是我所知的国内仅有的大模型平台，官方能提供 OpenAI/Claude/Gemini 模型，不知道是不是 2API 的渠道</li><li>官方提供300w免费token, 有效期一年，</li><li>速度很快，强烈推荐，能用各种模型</li><li><a href=https://www.qiniu.com/ai/chat>AI 大模型推理服务 - 七牛云</a></li></ul></li></ul><h2 id=国外厂商或平台>国外厂商或平台<a hidden class=anchor aria-hidden=true href=#国外厂商或平台>#</a></h2><h3 id=显卡一哥英伟达老黄的福利---nvidia-nim-api>显卡一哥英伟达老黄的福利 - Nvidia NIM API<a hidden class=anchor aria-hidden=true href=#显卡一哥英伟达老黄的福利---nvidia-nim-api>#</a></h3><ul><li>我觉得比openrouter更好用，似乎免费不限量</li><li>提供各种模型， 包括国外的模型: deepseek-v3.2, qwen3-coder-480b, kimi-k2-thinking, minimax-m2, mistral-large, devstral<ul><li>不支持: glm-4.6/4.7, minimax-m2.1</li></ul></li><li>还支持部分文生图模型, FLUX.1-dev免费 25 requests, 可以试试</li><li>Try NVIDIA NIM APIs<ul><li>限制 rpm: 40</li></ul></li></ul><h3 id=cerebras-inference>Cerebras Inference<a hidden class=anchor aria-hidden=true href=#cerebras-inference>#</a></h3><ul><li>我体验过的速度最快的大模型平台，速度可达 220+ token/s, S级推荐</li><li>提供的免费模型较少，经常更换，现在包括: glm-4.6, qwen-3-235b-a22b-instruct-2507, gpt-oss-120b, …</li><li>Rate Limits<ul><li>RPM: 10~30</li><li>TPD: 1M , 每天 100w token 有点不够用，但爽就完事了</li></ul></li></ul><h3 id=openrouter>OpenRouter<a hidden class=anchor aria-hidden=true href=#openrouter>#</a></h3><ul><li>长期稳定，模型丰富</li><li>API Rate Limits<ul><li>不充钱的用户每天 50 rpd, 充了10刀的用户每天 1000 rpd</li></ul></li><li>很多公益站都用了 OpenRouter 的渠道</li></ul><h3 id=mistral>Mistral<a hidden class=anchor aria-hidden=true href=#mistral>#</a></h3><ul><li>欧洲主流模型厂商，提供长期稳定的模型api</li><li>我试过在官方聊天网站 <a href=https://chat.mistral.ai/chat>Le Chat</a> 体验的效果很差，远不如国内的模型，</li><li>我还试过在本地用 Ollama / LM Studio 跑 mistral/devstral 系列的模型也远不如国内的qwen3-32b内的模型，但reddit论坛很多人都在吹mistral系列的模型，我觉得就是老欧人的自嗨</li><li>Rate Limits & Usage tiers<ul><li>免费额度非常大，</li><li>Tokens per Minute 500,000</li><li>Tokens per Month 1,000,000,000，大约每天 rpd 是 3300w</li></ul></li><li>Codestral<ul><li>mistral系列专注于coding的模型似乎有额外的免费额度，但我没用过，因为coding模型竞争太激烈了，有其他选择</li></ul></li></ul><h2 id=国外-others>国外 Others<a hidden class=anchor aria-hidden=true href=#国外-others>#</a></h2><ul><li><h3 id=groq><strong>groq</strong><a hidden class=anchor aria-hidden=true href=#groq>#</a></h3><ul><li>免费模型种类多，但大模型不多，大多是小模型， 免费额度较少</li><li>免费大模型包括: kimi-k2-instruct-0905, gpt-oss-120b, llama-4-maverick-17b-128e</li><li>Rate Limits<ul><li>rpm - 10~60</li><li>tokens per day 是 100K~500K, 每天的token太少了，不够用</li></ul></li></ul></li><li><h3 id=poe><strong>Poe</strong><a hidden class=anchor aria-hidden=true href=#poe>#</a></h3><ul><li><p>poe 既不是模型研发厂商，也不是聚合平台，主要业务是方便用户通过ui创建chat-bot和自动化任务bot，也提供了模型api供用户使用</p></li><li><p>免费用户每天发放 3000 points, 仅当日有效</p><ul><li><a href=https://help.poe.com/hc/en-us/articles/19944206309524-Poe-FAQs>Poe FAQs</a></li></ul></li><li><p>官方文档提到了支持 claude-code, cline, cursor, continue</p></li><li><blockquote><p>佬友 tips: 用之前建议一个个模型按费率和收费标准选一下，像 Grok-4.1-Fast 、Gemini Flash 系列、GPT-5-mini/GPT-5-nano 都不怎么耗积分</p></blockquote><p>我个人不推荐使用这家的api， 因为不支持结构化输出，这是ai非聊天类工具大多需要的基础功能</p><ul><li>Structured outputs are not supported</li><li>The <code>strict</code> parameter for function calling is ignored, which means the tool use JSON is not guaranteed to follow the supplied schema.</li><li><a href=https://creator.poe.com/docs/external-applications/openai-compatible-api>OpenAI Compatible API</a></li></ul></li></ul></li><li><h3 id=chutes><strong>Chutes</strong><a hidden class=anchor aria-hidden=true href=#chutes>#</a></h3><ul><li>目前限时免费的模型有4个: GLM 4.5 Air, Gpt Oss 20b, Gemma 3 4b, Tongyi DeepResearch 30B<ul><li>免费的模型参数不够大，不如其他平台</li><li><a href="https://chutes.ai/app?free=true">Chutes Free Models</a></li></ul></li><li>目前测试注册就可以用，不需要充钱，只写了限时免费，没找到请求速度限制说明</li><li>不推荐使用这个平台，因为免费规则经常调整，在25年7月需要充5刀了才给200rpd免费额度</li></ul></li><li><h3 id=zenmux><strong>ZenMux</strong><a hidden class=anchor aria-hidden=true href=#zenmux>#</a></h3><ul><li>目前提供了4个免费模型: gemini-3-flash-preview-free, xiaomi/mimo-v2-flash, kuaishou/kat-coder-pro-v1, z-ai/glm-4.6v-flash<ul><li><a href="https://zenmux.ai/models?sort=pricingLowToHigh">Free Models - ZenMux</a></li></ul></li><li>测试时gemini-3-flash返回异常429, xiaomi-mino能用但速度一般</li><li>这个平台我看25年8月才开始运营，是不是长期稳定还要让子弹飞一会儿，以后会关注更新</li></ul></li><li><h3 id=huggingface>Huggingface<a hidden class=anchor aria-hidden=true href=#huggingface>#</a></h3></li><li><h3 id=国外平台我用的少大家可以补充一些反馈和其他平台>国外平台我用的少，大家可以补充一些反馈和其他平台<a hidden class=anchor aria-hidden=true href=#国外平台我用的少大家可以补充一些反馈和其他平台>#</a></h3></li></ul><h1 id=其他>其他<a hidden class=anchor aria-hidden=true href=#其他>#</a></h1><ul><li>这么多免费大模型api，不知道有没有什么好的统一管理的方法</li></ul></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>Copyright © 2020-2025 Zhang Ranrui. All Rights Reserved.</span><br>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>