<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3988508441804851" crossorigin=anonymous></script><title>Python的协程详细解释 | 八戒的技术博客</title>
<meta name=keywords content><meta name=description content="在实际中遇到这样一个问题，公司软件发布上线自动化。
说简单点，就是需要去登录一个上线的内部网站，然后爬下所有的上线数据。
然后根据爬下来的数据整理好，可以一起上线的，就并发多线程，其实就是去传参数点击一个链接等返回。
不能并发的就单线程点链接。
那这个事情必须更有效率，单线程的没问题，用 python 的 request 就可以实现了。
我们仔细研究一下协程，先讲一下历史：
使用Python的人往往纠结在多线程、多进程，哪个效率更高？到底用哪个好呢？
其实 Python 的多进程和多线程，相对于别家的协程和异步处理机制，都不行，线程之间切换耗费 CPU 和寄存器，OS 的调度不可控，多进程之间通讯也不便。性能根本不行。
后来呢 Python 改进了语法，出现了 yiled from 充当协程调度，有人就根据这个特性开发了第三方的协程框架，Tornado，Gevent等。
官方也不能坐视不理啊，任凭别人出风头，于是 Python 之父深入简出3年，苦心钻研自家的协程，async/await 和 asyncio 库，并放到 Python3.5 后成为官方原生的协程。
对于 http请求、读写文件、读写数据库这种高延时的 IO 操作，协程是个大杀器，优点非常多；它可以在预料到一个阻塞将发生时，挂起当前协程，跑去执行其它协程，同时把事件注册到循环中，实现了多协程并发，其实这玩意是跟 Nodejs 的回调学的。
看下图，详细解释下，左边我们有100个网页请求，并发100个协程请求（其实也是1个1个发），当需要等待长时间回应回应时，挂起当前协程，并注册一个回调函数到事件循环（Event Loop）中，执行下一个协程，当有协程事件完成再通过回调函数唤醒挂起的协程，然后返回结果。

这个跟 nodejs 的回调函数基本一样，我们必须注意主进程和协程的关系，如果我在一个主进程中，触发协程函数，有100个协程，那么必须等待100个协程都结束后，才能回到正常的那个主进程中。当然，主进程也可能也是一个协程。
那么协程的基本用法


async f(n) 声明一个函数是协程的


await f(n) 挂起当前协程，把控制权交回 event loop，并且执行f(n)和注册之后的f(n)回调。
举个例子：如果在 g() 这个函数中执行了 await f()，那么g()函数会被挂起，并等待 f() 函数有结果结束，然后返回 g() 继续执行。


async def get(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response: 
            return await response.text() 
最后一行 await 是挂起命令，挂起当前函数 get() ，并执行 response.text() 和注册回调，等待 response.text() 执行完成后重新激活当前函數get()继续执行，返回。"><meta name=author content="八戒"><link rel=canonical href=https://rendoumi.com/posts/20211112-python_aiohttp/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5d8a858b4ad07d913988e10d3c3dbc8c171f45316a396de8a60d67f44840812d.css integrity="sha256-XYqFi0rQfZE5iOENPD28jBcfRTFqOW3opg1n9EhAgS0=" rel="preload stylesheet" as=style><link rel=icon href=https://rendoumi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rendoumi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rendoumi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://rendoumi.com/apple-touch-icon.png><link rel=mask-icon href=https://rendoumi.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://rendoumi.com/posts/20211112-python_aiohttp/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rendoumi.com/posts/20211112-python_aiohttp/"><meta property="og:site_name" content="八戒的技术博客"><meta property="og:title" content="Python的协程详细解释"><meta property="og:description" content="在实际中遇到这样一个问题，公司软件发布上线自动化。
说简单点，就是需要去登录一个上线的内部网站，然后爬下所有的上线数据。
然后根据爬下来的数据整理好，可以一起上线的，就并发多线程，其实就是去传参数点击一个链接等返回。
不能并发的就单线程点链接。
那这个事情必须更有效率，单线程的没问题，用 python 的 request 就可以实现了。
我们仔细研究一下协程，先讲一下历史：
使用Python的人往往纠结在多线程、多进程，哪个效率更高？到底用哪个好呢？
其实 Python 的多进程和多线程，相对于别家的协程和异步处理机制，都不行，线程之间切换耗费 CPU 和寄存器，OS 的调度不可控，多进程之间通讯也不便。性能根本不行。
后来呢 Python 改进了语法，出现了 yiled from 充当协程调度，有人就根据这个特性开发了第三方的协程框架，Tornado，Gevent等。
官方也不能坐视不理啊，任凭别人出风头，于是 Python 之父深入简出3年，苦心钻研自家的协程，async/await 和 asyncio 库，并放到 Python3.5 后成为官方原生的协程。
对于 http请求、读写文件、读写数据库这种高延时的 IO 操作，协程是个大杀器，优点非常多；它可以在预料到一个阻塞将发生时，挂起当前协程，跑去执行其它协程，同时把事件注册到循环中，实现了多协程并发，其实这玩意是跟 Nodejs 的回调学的。
看下图，详细解释下，左边我们有100个网页请求，并发100个协程请求（其实也是1个1个发），当需要等待长时间回应回应时，挂起当前协程，并注册一个回调函数到事件循环（Event Loop）中，执行下一个协程，当有协程事件完成再通过回调函数唤醒挂起的协程，然后返回结果。
这个跟 nodejs 的回调函数基本一样，我们必须注意主进程和协程的关系，如果我在一个主进程中，触发协程函数，有100个协程，那么必须等待100个协程都结束后，才能回到正常的那个主进程中。当然，主进程也可能也是一个协程。
那么协程的基本用法
async f(n) 声明一个函数是协程的
await f(n) 挂起当前协程，把控制权交回 event loop，并且执行f(n)和注册之后的f(n)回调。
举个例子：如果在 g() 这个函数中执行了 await f()，那么g()函数会被挂起，并等待 f() 函数有结果结束，然后返回 g() 继续执行。
async def get(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() 最后一行 await 是挂起命令，挂起当前函数 get() ，并执行 response.text() 和注册回调，等待 response.text() 执行完成后重新激活当前函數get()继续执行，返回。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-11-12T09:30:11+08:00"><meta property="article:modified_time" content="2021-11-12T09:30:11+08:00"><meta property="og:image" content="https://rendoumi.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://rendoumi.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Python的协程详细解释"><meta name=twitter:description content="在实际中遇到这样一个问题，公司软件发布上线自动化。
说简单点，就是需要去登录一个上线的内部网站，然后爬下所有的上线数据。
然后根据爬下来的数据整理好，可以一起上线的，就并发多线程，其实就是去传参数点击一个链接等返回。
不能并发的就单线程点链接。
那这个事情必须更有效率，单线程的没问题，用 python 的 request 就可以实现了。
我们仔细研究一下协程，先讲一下历史：
使用Python的人往往纠结在多线程、多进程，哪个效率更高？到底用哪个好呢？
其实 Python 的多进程和多线程，相对于别家的协程和异步处理机制，都不行，线程之间切换耗费 CPU 和寄存器，OS 的调度不可控，多进程之间通讯也不便。性能根本不行。
后来呢 Python 改进了语法，出现了 yiled from 充当协程调度，有人就根据这个特性开发了第三方的协程框架，Tornado，Gevent等。
官方也不能坐视不理啊，任凭别人出风头，于是 Python 之父深入简出3年，苦心钻研自家的协程，async/await 和 asyncio 库，并放到 Python3.5 后成为官方原生的协程。
对于 http请求、读写文件、读写数据库这种高延时的 IO 操作，协程是个大杀器，优点非常多；它可以在预料到一个阻塞将发生时，挂起当前协程，跑去执行其它协程，同时把事件注册到循环中，实现了多协程并发，其实这玩意是跟 Nodejs 的回调学的。
看下图，详细解释下，左边我们有100个网页请求，并发100个协程请求（其实也是1个1个发），当需要等待长时间回应回应时，挂起当前协程，并注册一个回调函数到事件循环（Event Loop）中，执行下一个协程，当有协程事件完成再通过回调函数唤醒挂起的协程，然后返回结果。

这个跟 nodejs 的回调函数基本一样，我们必须注意主进程和协程的关系，如果我在一个主进程中，触发协程函数，有100个协程，那么必须等待100个协程都结束后，才能回到正常的那个主进程中。当然，主进程也可能也是一个协程。
那么协程的基本用法


async f(n) 声明一个函数是协程的


await f(n) 挂起当前协程，把控制权交回 event loop，并且执行f(n)和注册之后的f(n)回调。
举个例子：如果在 g() 这个函数中执行了 await f()，那么g()函数会被挂起，并等待 f() 函数有结果结束，然后返回 g() 继续执行。


async def get(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response: 
            return await response.text() 
最后一行 await 是挂起命令，挂起当前函数 get() ，并执行 response.text() 和注册回调，等待 response.text() 执行完成后重新激活当前函數get()继续执行，返回。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"所有文章","item":"https://rendoumi.com/posts/"},{"@type":"ListItem","position":2,"name":"Python的协程详细解释","item":"https://rendoumi.com/posts/20211112-python_aiohttp/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Python的协程详细解释","name":"Python的协程详细解释","description":"在实际中遇到这样一个问题，公司软件发布上线自动化。\n说简单点，就是需要去登录一个上线的内部网站，然后爬下所有的上线数据。\n然后根据爬下来的数据整理好，可以一起上线的，就并发多线程，其实就是去传参数点击一个链接等返回。\n不能并发的就单线程点链接。\n那这个事情必须更有效率，单线程的没问题，用 python 的 request 就可以实现了。\n我们仔细研究一下协程，先讲一下历史：\n使用Python的人往往纠结在多线程、多进程，哪个效率更高？到底用哪个好呢？\n其实 Python 的多进程和多线程，相对于别家的协程和异步处理机制，都不行，线程之间切换耗费 CPU 和寄存器，OS 的调度不可控，多进程之间通讯也不便。性能根本不行。\n后来呢 Python 改进了语法，出现了 yiled from 充当协程调度，有人就根据这个特性开发了第三方的协程框架，Tornado，Gevent等。\n官方也不能坐视不理啊，任凭别人出风头，于是 Python 之父深入简出3年，苦心钻研自家的协程，async/await 和 asyncio 库，并放到 Python3.5 后成为官方原生的协程。\n对于 http请求、读写文件、读写数据库这种高延时的 IO 操作，协程是个大杀器，优点非常多；它可以在预料到一个阻塞将发生时，挂起当前协程，跑去执行其它协程，同时把事件注册到循环中，实现了多协程并发，其实这玩意是跟 Nodejs 的回调学的。\n看下图，详细解释下，左边我们有100个网页请求，并发100个协程请求（其实也是1个1个发），当需要等待长时间回应回应时，挂起当前协程，并注册一个回调函数到事件循环（Event Loop）中，执行下一个协程，当有协程事件完成再通过回调函数唤醒挂起的协程，然后返回结果。\n这个跟 nodejs 的回调函数基本一样，我们必须注意主进程和协程的关系，如果我在一个主进程中，触发协程函数，有100个协程，那么必须等待100个协程都结束后，才能回到正常的那个主进程中。当然，主进程也可能也是一个协程。\n那么协程的基本用法\nasync f(n) 声明一个函数是协程的\nawait f(n) 挂起当前协程，把控制权交回 event loop，并且执行f(n)和注册之后的f(n)回调。\n举个例子：如果在 g() 这个函数中执行了 await f()，那么g()函数会被挂起，并等待 f() 函数有结果结束，然后返回 g() 继续执行。\nasync def get(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() 最后一行 await 是挂起命令，挂起当前函数 get() ，并执行 response.text() 和注册回调，等待 response.text() 执行完成后重新激活当前函數get()继续执行，返回。\n","keywords":[],"articleBody":"在实际中遇到这样一个问题，公司软件发布上线自动化。\n说简单点，就是需要去登录一个上线的内部网站，然后爬下所有的上线数据。\n然后根据爬下来的数据整理好，可以一起上线的，就并发多线程，其实就是去传参数点击一个链接等返回。\n不能并发的就单线程点链接。\n那这个事情必须更有效率，单线程的没问题，用 python 的 request 就可以实现了。\n我们仔细研究一下协程，先讲一下历史：\n使用Python的人往往纠结在多线程、多进程，哪个效率更高？到底用哪个好呢？\n其实 Python 的多进程和多线程，相对于别家的协程和异步处理机制，都不行，线程之间切换耗费 CPU 和寄存器，OS 的调度不可控，多进程之间通讯也不便。性能根本不行。\n后来呢 Python 改进了语法，出现了 yiled from 充当协程调度，有人就根据这个特性开发了第三方的协程框架，Tornado，Gevent等。\n官方也不能坐视不理啊，任凭别人出风头，于是 Python 之父深入简出3年，苦心钻研自家的协程，async/await 和 asyncio 库，并放到 Python3.5 后成为官方原生的协程。\n对于 http请求、读写文件、读写数据库这种高延时的 IO 操作，协程是个大杀器，优点非常多；它可以在预料到一个阻塞将发生时，挂起当前协程，跑去执行其它协程，同时把事件注册到循环中，实现了多协程并发，其实这玩意是跟 Nodejs 的回调学的。\n看下图，详细解释下，左边我们有100个网页请求，并发100个协程请求（其实也是1个1个发），当需要等待长时间回应回应时，挂起当前协程，并注册一个回调函数到事件循环（Event Loop）中，执行下一个协程，当有协程事件完成再通过回调函数唤醒挂起的协程，然后返回结果。\n这个跟 nodejs 的回调函数基本一样，我们必须注意主进程和协程的关系，如果我在一个主进程中，触发协程函数，有100个协程，那么必须等待100个协程都结束后，才能回到正常的那个主进程中。当然，主进程也可能也是一个协程。\n那么协程的基本用法\nasync f(n) 声明一个函数是协程的\nawait f(n) 挂起当前协程，把控制权交回 event loop，并且执行f(n)和注册之后的f(n)回调。\n举个例子：如果在 g() 这个函数中执行了 await f()，那么g()函数会被挂起，并等待 f() 函数有结果结束，然后返回 g() 继续执行。\nasync def get(url): async with aiohttp.ClientSession() as session: async with session.get(url) as response: return await response.text() 最后一行 await 是挂起命令，挂起当前函数 get() ，并执行 response.text() 和注册回调，等待 response.text() 执行完成后重新激活当前函數get()继续执行，返回。\n所以 await 只叫做挂起是不太对的，感觉应该叫做 挂起并注册回调 比较合适。\n看以下程序，在 Python 3.7 之前，协程是这么用的：\nimport time import asyncio now = lambda : time.time() async def do_some_work(x): print('Waiting: ', x) start = now() coroutine = do_some_work(2) loop = asyncio.get_event_loop() loop.run_until_complete(coroutine) print('TIME: ', now() - start) 我们指定了一个协程 coroutine ，然后定义了一个事件循环 loop，loop 是需要 run_until_complete 所有的协程，然后交出控制权，返回正常的主进程。\n跟上图完全匹配。\n在 Python 3.7 之后，简化了用法，一句 asyncio.run 就可以了：\nasyncio.run(do_some_work(2)) 上面程序就变了，省了好多，但是副作用是第一次看到的人会不明白它是怎么进化过来的：\nimport time import asyncio now = lambda : time.time() async def do_some_work(x): print('Waiting: ', x) start = now() asyncio.run(do_some_work(2)) print('TIME: ', now() - start) 如果我们要访问一个网站的100个网页，单线程的做法是：请求一次，回来一次，然后进行下一个\nfor url in urls： response=get(url) results=parse(response) 这样效率很低，协程呢，做法就不同了，一次发起100个请求（准确的说也是一个一个发），不同的是协程不会死等返回，而是发一个请求，挂起，再发一个再挂起，发起100个，就挂起100个，然后注册并等待100个返回，效率提升了100倍。可以理解为同时做了100件事，做到由自己调度而不是交给CPU，程序的并发由自己来控制，而不是交由 OS 去调度，效率极大的提高了。\n进化到协程，我们把费 IO 的 get 函数抽出来放到协程里：\nasync def get(url:str): my_conn = aiohttp.TCPConnector(limit=10) async with aiohttp.ClientSession(connector=my_conn) as session: async with session.get(url) as resp: return await resp.text() for url in urls： response=asyncio.run(get(url)) results=parse(response) 具体到我们的项目，我们首先要登录一个网页拿到 cookie，这个过程其实就一个协程，没人会登录个几百次吧。然后把放了 cookie 的 session 取出来，供后面的协程再复用就可以了，示例代码如下：\nimport aiohttp import asyncio async def login(): my_conn = aiohttp.TCPConnector(limit=10) async with aiohttp.ClientSession(connector=my_conn) as session: data = {'loginname':'wangbadan','password':'Fuckyouall'} async with session.post('http://192.168.1.3/user/login',data=data) as resp: print(resp.url) print(resp.status) print(await resp.text()) return session session = asyncio.run(login()) print(f\"{session}\") 再给一个完全版的主函数是进程，下载是协程的例子，注意里面的 aiohttp.TCPConnector(limit=10)，限制一下并发是10个，否则会被服务器 Ban 掉：\nimport asyncio import time import aiohttp from aiohttp.client import ClientSession async def download_link(url:str,session:ClientSession): async with session.get(url) as response: result = await response.text() print(f'Read {len(result)} from {url}') async def download_all(urls:list): my_conn = aiohttp.TCPConnector(limit=10) async with aiohttp.ClientSession(connector=my_conn) as session: tasks = [] for url in urls: task = asyncio.ensure_future(download_link(url=url,session=session)) tasks.append(task) await asyncio.gather(*tasks,return_exceptions=True) # the await must be nest inside of the session url_list = [\"https://www.google.com\",\"https://www.bing.com\"]*50 print(url_list) start = time.time() asyncio.run(download_all(url_list)) end = time.time() print(f'download {len(url_list)} links in {end - start} seconds') 协程里的 session 也有很多种用法，参考下面的链接就好：\nhttps://blog.csdn.net/weixin_39643613/article/details/109171090\n我们也给出简单易用的线程池版，说不定以后会用上：\nimport requests from requests.sessions import Session import time from concurrent.futures import ThreadPoolExecutor from threading import Thread,local url_list = [\"https://www.google.com/\",\"https://www.bing.com\"]*50 thread_local = local() def get_session() -\u003e Session: if not hasattr(thread_local,'session'): thread_local.session = requests.Session() return thread_local.session def download_link(url:str): session = get_session() with session.get(url) as response: print(f'Read {len(response.content)} from {url}') def download_all(urls:list) -\u003e None: with ThreadPoolExecutor(max_workers=10) as executor: executor.map(download_link,url_list) start = time.time() download_all(url_list) end = time.time() print(f'download {len(url_list)} links in {end - start} seconds') ","wordCount":"402","inLanguage":"zh","image":"https://rendoumi.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2021-11-12T09:30:11+08:00","dateModified":"2021-11-12T09:30:11+08:00","author":{"@type":"Person","name":"八戒"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rendoumi.com/posts/20211112-python_aiohttp/"},"publisher":{"@type":"Organization","name":"八戒的技术博客","logo":{"@type":"ImageObject","url":"https://rendoumi.com/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://rendoumi.com/ accesskey=h title="Home (Alt + H)"><img src=https://rendoumi.com/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://rendoumi.com/ title=首页><span>首页</span></a></li><li><a href=https://rendoumi.com/posts/ title=文章><span>文章</span></a></li><li><a href=https://rendoumi.com/archives/ title=归档><span>归档</span></a></li><li><a href=https://blog.rendoumi.com title=生活><span>生活</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://rendoumi.com/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://rendoumi.com/>主页</a>&nbsp;»&nbsp;<a href=https://rendoumi.com/posts/>所有文章</a></div><h1 class="post-title entry-hint-parent">Python的协程详细解释
<span class=entry-hint title=Draft><svg height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2021-11-12 09:30:11 +0800 CST'>2021年11月12日</span>&nbsp;·&nbsp;<span>2 分钟</span>&nbsp;·&nbsp;<span>402 字</span>&nbsp;·&nbsp;<span>八戒</span></div></header><div class=post-content><p>在实际中遇到这样一个问题，公司软件发布上线自动化。</p><p>说简单点，就是需要去登录一个上线的内部网站，然后爬下所有的上线数据。</p><p>然后根据爬下来的数据整理好，可以一起上线的，就并发多线程，其实就是去传参数点击一个链接等返回。</p><p>不能并发的就单线程点链接。</p><p>那这个事情必须更有效率，单线程的没问题，用 python 的 request 就可以实现了。</p><p>我们仔细研究一下协程，先讲一下历史：</p><p>使用Python的人往往纠结在多线程、多进程，哪个效率更高？到底用哪个好呢？</p><p>其实 Python 的多进程和多线程，相对于别家的协程和异步处理机制，都不行，线程之间切换耗费 CPU 和寄存器，OS 的调度不可控，多进程之间通讯也不便。性能根本不行。</p><p>后来呢 Python 改进了语法，出现了 yiled from 充当协程调度，有人就根据这个特性开发了第三方的协程框架，Tornado，Gevent等。</p><p>官方也不能坐视不理啊，任凭别人出风头，于是 Python 之父深入简出3年，苦心钻研自家的协程，async/await 和 asyncio 库，并放到 Python3.5 后成为官方原生的协程。</p><p>对于 http请求、读写文件、读写数据库这种高延时的 IO 操作，协程是个大杀器，优点非常多；它可以在预料到一个阻塞将发生时，挂起当前协程，跑去执行其它协程，同时把事件注册到循环中，实现了多协程并发，其实这玩意是跟 Nodejs 的回调学的。</p><p>看下图，详细解释下，左边我们有100个网页请求，并发100个协程请求（其实也是1个1个发），当需要等待长时间回应回应时，挂起当前协程，并注册一个回调函数到事件循环（Event Loop）中，执行下一个协程，当有协程事件完成再通过回调函数唤醒挂起的协程，然后返回结果。</p><p><img loading=lazy src=/posts/20211112-python_aiohttp/image-20211112085624811.png></p><p>这个跟 nodejs 的回调函数基本一样，我们必须注意主进程和协程的关系，如果我在一个主进程中，触发协程函数，有100个协程，那么必须等待100个协程都结束后，才能回到正常的那个主进程中。当然，主进程也可能也是一个协程。</p><p>那么协程的基本用法</p><ul><li><p>async f(n) 声明一个函数是协程的</p></li><li><p>await f(n) 挂起当前协程，把控制权交回 event loop，并且执行f(n)和注册之后的f(n)回调。</p><p>举个例子：如果在 g() 这个函数中执行了 await f()，那么g()函数会被挂起，并等待 f() 函数有结果结束，然后返回 g() 继续执行。</p></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>get</span><span class=p>(</span><span class=n>url</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>with</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>ClientSession</span><span class=p>()</span> <span class=k>as</span> <span class=n>session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>async</span> <span class=k>with</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span> <span class=k>as</span> <span class=n>response</span><span class=p>:</span> 
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=k>await</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span><span class=p>()</span> 
</span></span></code></pre></div><p>最后一行 await 是挂起命令，挂起当前函数 get() ，并执行 response.text() 和注册回调，等待 response.text() 执行完成后重新激活当前函數get()继续执行，返回。</p><p>所以 await 只叫做挂起是不太对的，感觉应该叫做 <strong>挂起并注册回调</strong> 比较合适。</p><p>看以下程序，在 Python 3.7 之前，协程是这么用的：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>asyncio</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>now</span> <span class=o>=</span> <span class=k>lambda</span> <span class=p>:</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>do_some_work</span><span class=p>(</span><span class=n>x</span><span class=p>):</span> 
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Waiting: &#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>start</span> <span class=o>=</span> <span class=n>now</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>coroutine</span> <span class=o>=</span> <span class=n>do_some_work</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>loop</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>get_event_loop</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>loop</span><span class=o>.</span><span class=n>run_until_complete</span><span class=p>(</span><span class=n>coroutine</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;TIME: &#39;</span><span class=p>,</span> <span class=n>now</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span>
</span></span></code></pre></div><p>我们指定了一个协程 coroutine ，然后定义了一个事件循环 loop，loop 是需要 run_until_complete 所有的协程，然后交出控制权，返回正常的主进程。</p><p>跟上图完全匹配。</p><p><strong>在 Python 3.7 之后，简化了用法，一句 asyncio.run 就可以了：</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>do_some_work</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span>
</span></span></code></pre></div><p>上面程序就变了，省了好多，但是副作用是第一次看到的人会不明白它是怎么进化过来的：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>asyncio</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>now</span> <span class=o>=</span> <span class=k>lambda</span> <span class=p>:</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>do_some_work</span><span class=p>(</span><span class=n>x</span><span class=p>):</span> 
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Waiting: &#39;</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>start</span> <span class=o>=</span> <span class=n>now</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>do_some_work</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;TIME: &#39;</span><span class=p>,</span> <span class=n>now</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span>
</span></span></code></pre></div><p>如果我们要访问一个网站的100个网页，单线程的做法是：请求一次，回来一次，然后进行下一个</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>url</span> <span class=ow>in</span> <span class=n>urls</span><span class=err>：</span>
</span></span><span class=line><span class=cl>  <span class=n>response</span><span class=o>=</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>results</span><span class=o>=</span><span class=n>parse</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span></code></pre></div><p>这样效率很低，协程呢，做法就不同了，一次发起100个请求（准确的说也是一个一个发），不同的是协程不会死等返回，而是发一个请求，挂起，再发一个再挂起，发起100个，就挂起100个，然后注册并等待100个返回，效率提升了100倍。可以理解为同时做了100件事，做到由自己调度而不是交给CPU，程序的并发由自己来控制，而不是交由 OS 去调度，效率极大的提高了。</p><p>进化到协程，我们把费 IO 的 get 函数抽出来放到协程里：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>get</span><span class=p>(</span><span class=n>url</span><span class=p>:</span><span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>my_conn</span> <span class=o>=</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>TCPConnector</span><span class=p>(</span><span class=n>limit</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>with</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>ClientSession</span><span class=p>(</span><span class=n>connector</span><span class=o>=</span><span class=n>my_conn</span><span class=p>)</span> <span class=k>as</span> <span class=n>session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>async</span> <span class=k>with</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span> <span class=k>as</span> <span class=n>resp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=k>await</span> <span class=n>resp</span><span class=o>.</span><span class=n>text</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>url</span> <span class=ow>in</span> <span class=n>urls</span><span class=err>：</span>
</span></span><span class=line><span class=cl>  <span class=n>response</span><span class=o>=</span><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>results</span><span class=o>=</span><span class=n>parse</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span></code></pre></div><p>具体到我们的项目，我们首先要登录一个网页拿到 cookie，这个过程其实就一个协程，没人会登录个几百次吧。然后把放了 cookie 的 session 取出来，供后面的协程再复用就可以了，示例代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>aiohttp</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>asyncio</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>login</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>my_conn</span> <span class=o>=</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>TCPConnector</span><span class=p>(</span><span class=n>limit</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>with</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>ClientSession</span><span class=p>(</span><span class=n>connector</span><span class=o>=</span><span class=n>my_conn</span><span class=p>)</span> <span class=k>as</span> <span class=n>session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>data</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;loginname&#39;</span><span class=p>:</span><span class=s1>&#39;wangbadan&#39;</span><span class=p>,</span><span class=s1>&#39;password&#39;</span><span class=p>:</span><span class=s1>&#39;Fuckyouall&#39;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>async</span> <span class=k>with</span> <span class=n>session</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=s1>&#39;http://192.168.1.3/user/login&#39;</span><span class=p>,</span><span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=p>)</span> <span class=k>as</span> <span class=n>resp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>resp</span><span class=o>.</span><span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>resp</span><span class=o>.</span><span class=n>status</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=k>await</span> <span class=n>resp</span><span class=o>.</span><span class=n>text</span><span class=p>())</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>session</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>session</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>login</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>session</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>再给一个完全版的主函数是进程，下载是协程的例子，注意里面的 aiohttp.TCPConnector(limit=10)，限制一下并发是10个，否则会被服务器 Ban 掉：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>asyncio</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span> 
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>aiohttp</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>aiohttp.client</span> <span class=kn>import</span> <span class=n>ClientSession</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>download_link</span><span class=p>(</span><span class=n>url</span><span class=p>:</span><span class=nb>str</span><span class=p>,</span><span class=n>session</span><span class=p>:</span><span class=n>ClientSession</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>with</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span> <span class=k>as</span> <span class=n>response</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Read </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>result</span><span class=p>)</span><span class=si>}</span><span class=s1> from </span><span class=si>{</span><span class=n>url</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>download_all</span><span class=p>(</span><span class=n>urls</span><span class=p>:</span><span class=nb>list</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>my_conn</span> <span class=o>=</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>TCPConnector</span><span class=p>(</span><span class=n>limit</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>with</span> <span class=n>aiohttp</span><span class=o>.</span><span class=n>ClientSession</span><span class=p>(</span><span class=n>connector</span><span class=o>=</span><span class=n>my_conn</span><span class=p>)</span> <span class=k>as</span> <span class=n>session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>tasks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>url</span> <span class=ow>in</span> <span class=n>urls</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>task</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>ensure_future</span><span class=p>(</span><span class=n>download_link</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>session</span><span class=o>=</span><span class=n>session</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>tasks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>task</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>*</span><span class=n>tasks</span><span class=p>,</span><span class=n>return_exceptions</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=c1># the await must be nest inside of the session</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>url_list</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;https://www.google.com&#34;</span><span class=p>,</span><span class=s2>&#34;https://www.bing.com&#34;</span><span class=p>]</span><span class=o>*</span><span class=mi>50</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>url_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>asyncio</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>download_all</span><span class=p>(</span><span class=n>url_list</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>end</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;download </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>url_list</span><span class=p>)</span><span class=si>}</span><span class=s1> links in </span><span class=si>{</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=si>}</span><span class=s1> seconds&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>协程里的 session 也有很多种用法，参考下面的链接就好：</p><p><a href=https://blog.csdn.net/weixin_39643613/article/details/109171090>https://blog.csdn.net/weixin_39643613/article/details/109171090</a></p><p>我们也给出简单易用的线程池版，说不定以后会用上：</p><p><img alt=image-20211112091410467 loading=lazy src=/posts/20211112-python_aiohttp/image-20211112091410467.png></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>requests.sessions</span> <span class=kn>import</span> <span class=n>Session</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>concurrent.futures</span> <span class=kn>import</span> <span class=n>ThreadPoolExecutor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>threading</span> <span class=kn>import</span> <span class=n>Thread</span><span class=p>,</span><span class=n>local</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>url_list</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;https://www.google.com/&#34;</span><span class=p>,</span><span class=s2>&#34;https://www.bing.com&#34;</span><span class=p>]</span><span class=o>*</span><span class=mi>50</span>
</span></span><span class=line><span class=cl><span class=n>thread_local</span> <span class=o>=</span> <span class=n>local</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_session</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>thread_local</span><span class=p>,</span><span class=s1>&#39;session&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>thread_local</span><span class=o>.</span><span class=n>session</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>Session</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>thread_local</span><span class=o>.</span><span class=n>session</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>download_link</span><span class=p>(</span><span class=n>url</span><span class=p>:</span><span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>session</span> <span class=o>=</span> <span class=n>get_session</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span> <span class=k>as</span> <span class=n>response</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Read </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>content</span><span class=p>)</span><span class=si>}</span><span class=s1> from </span><span class=si>{</span><span class=n>url</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>download_all</span><span class=p>(</span><span class=n>urls</span><span class=p>:</span><span class=nb>list</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>ThreadPoolExecutor</span><span class=p>(</span><span class=n>max_workers</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span> <span class=k>as</span> <span class=n>executor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>executor</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>download_link</span><span class=p>,</span><span class=n>url_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>download_all</span><span class=p>(</span><span class=n>url_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>end</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;download </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>url_list</span><span class=p>)</span><span class=si>}</span><span class=s1> links in </span><span class=si>{</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=si>}</span><span class=s1> seconds&#39;</span><span class=p>)</span>
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://rendoumi.com/posts/20211115-gluster_tuning/><span class=title>« 上一页</span><br><span>GlusterFS文件系统的优化</span>
</a><a class=next href=https://rendoumi.com/posts/20211111-k8s_filebeat/><span class=title>下一页 »</span><br><span>kubernetes使用filebeat multiline自定义收集日志</span></a></nav></footer><div id=comments></div><script src=https://cwd.js.org/cwd.js></script><script>const comments=new CWDComments({el:"#comments",apiBaseUrl:"https://cwd.rendoumi.qzz.io"});comments.mount()</script></article></main><footer class=footer><span>Copyright © 2020-2025 Zhang Ranrui. All Rights Reserved.</span><br>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>