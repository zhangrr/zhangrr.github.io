<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3988508441804851" crossorigin=anonymous></script><title>所有文章 | 八戒的技术博客</title>
<meta name=keywords content><meta name=description content="所有文章 - 八戒的技术博客"><meta name=author content><link rel=canonical href=https://rendoumi.com/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5d8a858b4ad07d913988e10d3c3dbc8c171f45316a396de8a60d67f44840812d.css integrity="sha256-XYqFi0rQfZE5iOENPD28jBcfRTFqOW3opg1n9EhAgS0=" rel="preload stylesheet" as=style><link rel=icon href=https://rendoumi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rendoumi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rendoumi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://rendoumi.com/apple-touch-icon.png><link rel=mask-icon href=https://rendoumi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://rendoumi.com/posts/index.xml title=rss><link rel=alternate hreflang=zh href=https://rendoumi.com/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rendoumi.com/posts/"><meta property="og:site_name" content="八戒的技术博客"><meta property="og:title" content="所有文章"><meta property="og:locale" content="zh"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="所有文章"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"所有文章","item":"https://rendoumi.com/posts/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://rendoumi.com/ accesskey=h title="八戒的技术博客 (Alt + H)">八戒的技术博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rendoumi.com/ title=首页><span>首页</span></a></li><li><a href=https://rendoumi.com/posts/ title=文章><span class=active>文章</span></a></li><li><a href=https://rendoumi.com/archives/ title=归档><span>归档</span></a></li><li><a href=https://blog.rendoumi.com title=生活><span>生活</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://rendoumi.com/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>所有文章</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>OPNsense的远程安装并访问WEBGUI
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>OPNsense安装其实很容易，但是远程装就不那么好玩了。
尤其涉及到内网WEBGUI的访问，缺省安装完成以后，只能从内网口访问管理界面，问题是VPC里只有一台Linux机器，还没有浏览器，怎么办？
记录一下安装过程，备查：
一、下载iso镜像并解压 wget https://pkg.opnsense.org/releases/25.7/OPNsense-25.7-dvd-amd64.iso.bz2 bzip2 -d OPNsense-25.7-dvd-amd64.iso.bz2 二、kvm用virt-install安装iso，注意桥接了2个网卡 #!/bin/bash mkdir -p /export/kvm/opn/ qemu-img create -f qcow2 /export/kvm/opn/opn.qcow2 20G virt-install \ --name=opn \ --vcpu=2 \ --ram=2048 \ --disk path=/export/kvm/opn/opn.qcow2,format=qcow2,size=20 \ --cdrom=/export/kvm/iso/OPNsense-25.7-dvd-amd64.iso \ --network bridge=br0,model=virtio \ --network bridge=br1,model=virtio \ --os-type unix \ --os-variant freebsd13.1 \ --vnc --vnclisten=0.0.0.0 --vncport=5901 三、vnc连到port 5901上进行安装配置 OPNsense公网的网卡、ip、mask、gateway配置
OPNsense内网的网卡、ip、mask配置
四、设置内网访问 这里就非常鬼畜了，首先在内网的那台机器上做port转发，这台机器是192.168.100.2，做个systemd的service:
cat /etc/systemd/system/opn-proxy.service [Unit] After=network.target Wants=network.target [Service] WorkingDirectory=/usr/local/bin/ Type=simple ExecStart=/usr/local/bin/go-tcp-proxy_1.0.2_linux_amd64 -l ":4430" -r "192.168.100.1:4430" Restart=on-failure RestartSec=1s [Install] WantedBy=multi-user.target 如上的话，如果web访问http://192.168.100.2:4430，那Host: 192.168.100.1 会被转发给 192.168.100.1 的OPNsense的4430端口
那OPNsense的内网IP是192.168.100.1，登录用户是root，密码是xxxxxxxx
从vnc上登录，然后进入shell，找到webgui的部分，添加port和althostnames的两项
vi /conf/config.xml ...... &lt;webgui> &lt;protocol>https&lt;/protocol> &lt;ssl-certref>68adc26101eeb&lt;/ssl-certref> &lt;port>4430&lt;/port> &lt;althostnames>192.168.100.2&lt;/althostnames> &lt;/webgui> ...... 然后重启webgui
...</p></div><footer class=entry-footer><span title='2025-10-23 09:01:11 +0800 CST'>2025年10月23日</span></footer><a class=entry-link aria-label="post link to OPNsense的远程安装并访问WEBGUI" href=https://rendoumi.com/posts/20251023-opnsense_install/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>strapi的安装
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>老实说，strapi的安装真的不是一件容易的事情。
第一步想简单化，于是就用Docker compose来安装，结果并不容易，官方文档不可用，改了半天终于跑起来，然后，嘿嘿，dockerhub上的strapi:latest 早就过期很久了。
于是又琢磨它那个Docker build版本的，问题是，都在宿主机环境build出来了，然后再放到Docker镜像中跑，岂不是脱裤子放屁，多此一举么。
于是回到原点，需要在CLI环境下安装，然后要部署到正式生产环境。
步骤如下：
一、装mysql 8.0 apt install wget lsb-release gnupg -y wget https://dev.mysql.com/get/mysql-apt-config_0.8.29-1_all.deb dpkg -i mysql-apt-config_0.8.29-1_all.deb apt update apt install mysql-server 二、装NVM，nodejs和yarn curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.4/install.sh | bash source ~/.nvm/nvm.sh nvm ls-remote nvm install v20.19.5 node -v npm install -g yarn npm list -g 三、初始化strapi mkdir /data cd /data yarn create strapi # 我们要跳过它那个免费30天的grow方案 # 然后数据库是 mysql , 填入mysql的一系列参数 # 使用ts 四、配置strapi # 加入自己的域名 vi /data/strapi/config/server.ts export default ({ env }) => ({ host: env('HOST', '0.0.0.0'), port: env.int('PORT', 1337), url: 'https://blog.rendoumi.com', app: { keys: env.array('APP_KEYS'), }, }); # 建立新文件 vi /data/strapi/src/admin/vite.config.ts import { defineConfig, mergeConfig } from 'vite'; export default (config) => { return mergeConfig(config, defineConfig({ resolve: { alias: { '@': '/src', }, }, server: { allowedHosts: true } })); }; 五、安装nginx，运行程序 apt install nginx # 注释掉无用配置 vi /etc/nginx/nginx.conf # include /etc/nginx/sites-enabled/*; # 新增配置 vi /etc/nginx/conf.d/strapi.conf upstream strapi { server 127.0.0.1:1337; } server { # Listen HTTP listen 80; server_name blog.rendoumi.com; # Redirect HTTP to HTTPS return 301 https://$host$request_uri; } server { # Listen HTTPS listen 443 ssl; server_name webcms.yoov.com; # SSL config ssl_certificate /usr/local/bin/certs/certificates/blog.rendoumi.com.crt; ssl_certificate_key /usr/local/bin/certs/certificates/blog.rendoumi.com.key; # Proxy Config location / { proxy_pass http://strapi; proxy_http_version 1.1; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Host $http_host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "Upgrade"; proxy_pass_request_headers on; } } cd /data/strapi yarn develop 然后登录就可以了，诡异的是第四步，如果不gen vite.config.ts，那nginx代理访问local host:1337上会出问题。
...</p></div><footer class=entry-footer><span title='2025-10-16 09:01:11 +0800 CST'>2025年10月16日</span></footer><a class=entry-link aria-label="post link to strapi的安装" href=https://rendoumi.com/posts/20251016-strapi/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>NVM管理的Nodejs如何做成systemd的serivce服务
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>有很多next、nuxt、yarn的nodejs程序，都是什么npm start或者yarn develop的启动模式，如何搞成systemd的服务呢，这里面麻烦的就是systemd的服务需要使用全路径。
那方法如下：
一、安装nvm curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.4/install.sh | bash 二、安装nodejs和yarn source ~/.nvm/nvm.sh nvm ls-remote nvm install v20.19.5 node -v npm install -g yarn npm list -g 三、弄strapi.service服务 echo $NVM_DIR # 确定 nvm 的安装目录 /root/.nvm which node # 确定 Node.js 的路径 /root/.nvm/versions/node/v20.19.5/bin/node which yarn # 确定 Yarn 的路径 /root/.nvm/versions/node/v20.19.5/bin/yarn cat &lt; EOF > /etc/systemd/system/strapi.service [Unit] Description=Strapi App After=network.target [Service] # 使用用户账户运行服务，替换为实际的用户名 User=root Group=root # 指定工作目录，替换为项目的实际路径 WorkingDirectory=/data/strapi # 加载 nvm 并运行 yarn 或 node Environment="NVM_DIR=/root/.nvm" ExecStart=/bin/bash -c ". $NVM_DIR/nvm.sh && yarn develop" Restart=always RestartSec=10 [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now strapi</p></div><footer class=entry-footer><span title='2025-10-15 09:10:11 +0800 CST'>2025年10月15日</span></footer><a class=entry-link aria-label="post link to NVM管理的Nodejs如何做成systemd的serivce服务" href=https://rendoumi.com/posts/20251015-nodejs_systemctl/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>OPNsense如何做LoadBalance接入后端的Kubernetes nginx ingress --- Nginx篇
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>新托管了一个机房服务器，基本全用开源软件来构建：
那Firewall就用的OPNsense，后端自建Kubernetes，那OPNsense需要当作一个LoadBalance来使用
结构图如下，证书是放在了Nginx ingres上：
那方法有很多，各有利弊，说下第三个，Nginx的做法
relayd和caddy都说完了，那还有Nginx，Nginx的话，如果证书挂在OPNsense，那就可以用WAF的功能
如果证书放在后端Kubernetes的Nginx ingress上，那就无法用WAF了，算是data stream
那提前说一句，Nginx的配置是有Bug的，如果无法清除干净，需要ssh登录opnsense，然后
把 /conf/下xml配置文件中的 nginx 部分删除掉，然后重启服务器，才可以
os-nginx的配置方法如下：
第一步：首先去Upstream的Upstream Server子标签，建立两组服务器
第二步：再去Upstream的Upstream子标签，建立两组服务
建立的时候advanced mode要打开，PROXY Protocol要选中，Server选中各自的4个服务器，其它保持缺省即可。
第三步：去Data Streams的子标签Stream Servers，建两组服务
编辑一下，监听端口只选指定IP的80和443，PROXY Protocol不要选中，然后Route就选Upstream，Upstream Servers选中对应的，其它缺省即可。
那对应的，后端Kubernetes的Nginx ingress也要做相应配置
Nginx ingress的configmap，需要加上Proxy Protocol的部分
我们用的是官网的 ingress-nginx，配置文件是 ingress-nginx 的namespace中
configmap ingress-nginx-controller，内容如下，对应data那两行：
apiVersion: v1 data: use-proxy-protocol: "true" kind: ConfigMap metadata: annotations: meta.helm.sh/release-name: ingress-nginx meta.helm.sh/release-namespace: ingress-nginx nginx.ingress.kubernetes.io/configuration-snippet: "true" nginx.ingress.kubernetes.io/location-snippet: "true" nginx.ingress.kubernetes.io/server-snippet: "true" creationTimestamp: "2025-08-27T07:38:49Z" labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.13.1 helm.sh/chart: ingress-nginx-4.13.1 name: ingress-nginx-controller namespace: ingress-nginx resourceVersion: "22298827" uid: d6eeef3c-7e44-4667-854a-c7693006b221 编辑后，nginx ingress会自动reload
...</p></div><footer class=entry-footer><span title='2025-10-14 09:10:11 +0800 CST'>2025年10月14日</span></footer><a class=entry-link aria-label="post link to OPNsense如何做LoadBalance接入后端的Kubernetes nginx ingress --- Nginx篇" href=https://rendoumi.com/posts/20251014-opensense_nginx/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>OPNsense如何做LoadBalance接入后端的Kubernetes nginx ingress --- caddy篇
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>新托管了一个机房服务器，基本全用开源软件来构建：
那Firewall就用的OPNsense，后端自建Kubernetes，那OPNsense需要当作一个LoadBalance来使用
结构图如下，证书是放在了Nginx ingres上：
那方法有很多，各有利弊，说下第二个，Caddy的做法
Caddy真的是王道，什么泛域名，一个端口跑3个协议，都可以
用到Caddy，就要解决后端Nginx ingress无法获得客户真实IP的问题
Caddy配置如下：
General Settings：
Enable Layer4 Proxy 要勾选上
Auto HTTPS 要选中Off
其它保持默认，然后去到Layer4 Proxy进行配置，同样要配2个，一个HTTP，一个TLS
编辑HTTP的代理，注意 Domain 的地方需要把用到的所有域名列进去
编译TLS的代理
注意上面，Proxy Protocol都要选中v2，这样客户端真实IP才可以透传给后端的Nginx ingress
那同样后端的Nginx ingress的configmap，也需要加上Proxy Protocol的部分
我们用的是官网的 ingress-nginx，配置文件是 ingress-nginx 的namespace中
configmap ingress-nginx-controller，内容如下
apiVersion: v1 data: use-proxy-protocol: "true" kind: ConfigMap metadata: annotations: meta.helm.sh/release-name: ingress-nginx meta.helm.sh/release-namespace: ingress-nginx nginx.ingress.kubernetes.io/configuration-snippet: "true" nginx.ingress.kubernetes.io/location-snippet: "true" nginx.ingress.kubernetes.io/server-snippet: "true" creationTimestamp: "2025-08-27T07:38:49Z" labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.13.1 helm.sh/chart: ingress-nginx-4.13.1 name: ingress-nginx-controller namespace: ingress-nginx resourceVersion: "22298827" uid: d6eeef3c-7e44-4667-854a-c7693006b221 编辑后，nginx ingress会自动reload
...</p></div><footer class=entry-footer><span title='2025-10-14 09:05:11 +0800 CST'>2025年10月14日</span></footer><a class=entry-link aria-label="post link to OPNsense如何做LoadBalance接入后端的Kubernetes nginx ingress --- caddy篇" href=https://rendoumi.com/posts/20251014-opnsense_caddy/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>OPNsense如何做LoadBalance接入后端的Kubernetes nginx ingress --- relayd篇
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>新托管了一个机房服务器，基本全用开源软件来构建：
那Firewall就用的OPNsense，后端自建Kubernetes，那OPNsense需要当作一个LoadBalance来使用
结构图如下，证书是放在了Nginx ingres上：
那方法有很多，各有利弊，先说第一个，relayd的做法
relayd是最早的OPNsense的插件，用来做负载均衡，安装这个plugin插件
配置如下：
General Settings：
由于虚机的cpu是4个，所以进程设置成4
Backend Hosts:
后端节点有4个，只写IP即可
Table Checks：
端口检查，因为是直通，所以就设置成TCP检查即可
Tables：
Hosts选中4个节点
Virtual Server：
80和443各有一个
每个呢，设置好前面的监听地址和端口，后端的Table 服务器和Table check的协议，就ok了
最后去 General Settings 选中 Enable Relayd，然后save，就可以了
这么多贴图，是因为如果从CLI配置，其实就一个很简单的relayd.conf文本文件
但是从GUI，就一大堆，而且生成的东西简直不知所云
这样做relayd就相当于一个直通的LoadBalance，把流量送入后端的Nginx ingress所开的NodePort。
这样就可用了。
这样有个弊端，Nginx的ingress拿不到客户端的真实IP，X-forwarded-for无法传过来真的客户端IP，网上查文档是可以的，但是从GUI配了半天，也不知道怎么配，服了也是。</p></div><footer class=entry-footer><span title='2025-10-14 09:01:11 +0800 CST'>2025年10月14日</span></footer><a class=entry-link aria-label="post link to OPNsense如何做LoadBalance接入后端的Kubernetes nginx ingress --- relayd篇" href=https://rendoumi.com/posts/20251014-opnsense_relayd/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>seaweedfs的s3进阶试用方法
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>SeaweedFS 已经用docker compose的方式部署在生产环境内中了，对外只开放了一个S3的端口127.0.0.1:8333，然后前面套上Caddy的https代理，这样很安全了。
那进阶的要求又来了：
一、S3的pre signed的URL 由于程序之前是在AWS跑的，所以用了S3的最佳实践，pre sign url来进行上传和下载，那seaweedfs也是完全支持的，基本是无缝修改
给出验证程序：
import boto3 from botocore.client import Config # Configure the S3 client to point to your SeaweedFS S3 gateway s3_client = boto3.client( 's3', endpoint_url='https://s3.rendoumi.com', # Replace with your SeaweedFS S3 gateway address aws_access_key_id='aaaaaaaa', aws_secret_access_key='bbbbbbb', config=Config(signature_version='s3v4') ) bucket_name = 'myfiles' object_key = 'your-object-key' expiration_seconds = 3600 # URL valid for 1 hour # Generate a pre-signed URL for uploading (PUT) try: upload_url = s3_client.generate_presigned_url( 'put_object', Params={'Bucket': bucket_name, 'Key': object_key, 'ContentType': 'application/octet-stream'}, ExpiresIn=expiration_seconds ) print(f"Pre-signed URL for upload: {upload_url}") except Exception as e: print(f"Error generating upload URL: {e}") # Generate a pre-signed URL for downloading (GET) try: download_url = s3_client.generate_presigned_url( 'get_object', Params={'Bucket': bucket_name, 'Key': object_key}, ExpiresIn=expiration_seconds ) print(f"Pre-signed URL for download: {download_url}") except Exception as e: print(f"Error generating download URL: {e}") 能看到临时生成的upload的URL和download的URL，是完美支持的
...</p></div><footer class=entry-footer><span title='2025-09-17 09:01:11 +0800 CST'>2025年9月17日</span></footer><a class=entry-link aria-label="post link to seaweedfs的s3进阶试用方法" href=https://rendoumi.com/posts/20250917-seaweedfs_prod/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Postgres pgbackrest备份以及指定时间点恢复
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>最近狠折腾了一通postgres的备份，跟MySQL的阿里RDB恢复一样，如何不停止数据库服务，恢复某个表的数据到某个时间点，然后放到另一个表中呢？
其实用之前的wal恢复一样的，就是要把当天实例的全备份和wal都复制到另外一台上，然后恢复，再把数据给dump下来，再建一个新表，把数据导回去。
Postgres的wal和PITR时间点恢复
用pgbackrest感觉会好一些，其实都差不多，步骤如下：
一、安装并配置pgbackrest apt install pgbackrest # 建立备份的大本营 mkdir -p /var/lib/pgbackrest chmod 750 /var/lib/pgbackrest chown postgres:postgres /var/lib/pgbackrest # 编辑 /etc/pgbackrest.conf [global] repo1-path=/var/lib/pgbackrest repo1-retention-full=26 repo1-retention-archive=180 log-level-file=info log-level-console=info [global:archive-push] compress-level=3 [main] pg1-path=/var/lib/postgresql/13/main pg1-port=5432 讲解一下参数
global里面是全局配置
repo1-path=/var/lib/pgbackrest # pgBackRest 存储库路径 repo1-retention-full=26 # 保留最近的 26 个全量备份，大概6个月，180天 repo1-retention-archive=180 # 保留最近 180 天的 WAL 日志 log-level-file=info # 文件日志级别 log-level-console=info # 控制台日志级别 global:archive-push 设置的是wal归档的保存方式是压缩保存
main部分设置的是要备份的postgres源的路径和端口，【main】是stanza的名字
上面的备份其实有三种备份，full和incr和wal备份，那如果full和增量都没了，只要wal还在，那么依然能恢复到180天之内的某个时间点。wal很占空间，full也很占空间，一定要算准了。
那其实pgbackrest是用postgres身份去执行命令的，所以不用认证身份。
二、配置postgres vi /etc/postgresql/13/main/postgresql.conf # wal归档方法： #archive_mode = on #archive_command = 'cp %p /data/backup/%f' # pgbackrest归档方法： archive_mode = on archive_command = 'pgbackrest --stanza=main archive-push %p' wal_level = replica #备份级别是副本 max_wal_senders = 3 #最多wal日志发到3个客户端去 # 需要重启postgres systemctl restart postgresql 三、测试pgbackrest的备份功能 # 建立一个stanza sudo -u postgres pgbackrest --stanza=main --log-level-console=info stanza-create # 检查 sudo -u postgres pgbackrest --stanza=main --log-level-console=info check # 查看信息 sudo -u postgres pgbackrest info ...</p></div><footer class=entry-footer><span title='2025-09-15 10:01:11 +0800 CST'>2025年9月15日</span></footer><a class=entry-link aria-label="post link to Postgres pgbackrest备份以及指定时间点恢复" href=https://rendoumi.com/posts/20250915-pgbackrest_restore/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>seaweed S3服务单机版正式环境的部署
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>公司要做系统迁移，从AWS迁移到自建机房，那迁移的项目就一大堆，S3也在其中之列。
找来找去，第一首选的替代软件是minio，可是万恶的minio团队在这个时间点，已经后台移除了 admin 相关的操作权限
要想用呢，只能用个老版本的：quay.io/minio/minio:RELEASE.2025-04-22T22-12-26Z
那只能再找了，于是找到了SeaweedFS，这个软件其实是个彻头彻尾的单文件，但是分布式全集群架构
简单的说，就是一个软件，包含了10几种功能。
而我们呢，其实就要它的一个功能s3，而且要用于生产。网上一大堆的教程都是各种分布式的部署，如果机器足够，大家可以参考网上教程。
我们单台机器，硬盘底层是raid10，然后上层就只提供s3，而且要配置简单，没有什么安全问题，这台机器是直接暴露公网IP的。
那最简单的方法就是Docker compose，而且只放开s3的指定端口：
services: seaweedfs-s3: image: chrislusf/seaweedfs container_name: seaweedfs-s3 volumes: - ./data:/data - ./config/config.json:/seaweedfs/config.json ports: - "127.0.0.1:8333:8333" # - "9333:9333" entrypoint: /bin/sh -c command: | "echo 'Starting SeaweedFS S3 server' && \ weed server -dir=/data -volume.max=120 -s3 -s3.config /seaweedfs/config.json" restart: unless-stopped 仔细解释上面的参数：
ports 只开了 127.0.0.1:8333 的S3端口，其它都不开，如果需要查看服务状态，可以临时打开9333端口查看，看完再关 -volume.max=120，这个务必要注意，seaweed是分卷的，一个卷最多30G，缺省是8个卷。那缺省就是只有240G的容量，我们的硬盘是4T的，剩余3.7TB，那算下来，30*120=3600G=3.6T。这样就对准了，这个参数一定要根据生产的实际情况进行调整. 另外还把config.json的配置文件给mount入docker卷中了，配置文件里放的就是S3的IAM访问权限控制 详细看一下config.json
{ "identities": [ { "name": "admin", "credentials": [ { "accessKey": "aaa", "secretKey": "bbb" } ], "actions": [ "Admin", "Read", "List", "Tagging", "Write" ] }, { "name": "goods", "credentials": [ { "accessKey": "ccc", "secretKey": "ddd" } ], "actions": [ "Read:goods", "Write:goods", "List:goods", "Tagging:goods", "Admin:goods" ] } ] } 解释一下，上面定义了一个admin用户，可以对所有s3进行读写和管理。
...</p></div><footer class=entry-footer><span title='2025-09-15 09:01:11 +0800 CST'>2025年9月15日</span></footer><a class=entry-link aria-label="post link to seaweed S3服务单机版正式环境的部署" href=https://rendoumi.com/posts/20250915-seeweed_single_deploy/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>生产环境Elasticsearch 8单节点Docker-compose的安装方法
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>要在生产环境建一套Elasticsearch 8.0，单节点搭配Kibana，确实是困难重重，新版本需要TLS验证了
现在这个时间节点，2025年9月2日，Elasticsearch最新版本是9.0，后撤2个版本是8.18.6
那就用这个版本了，然后根据官方的文档会把人搞糊涂的。
正确的方法如下：
一、建立自签的证书 其实可以用ACME的证书，但是没有人会三个月就去重启一下ES的容器，更新证书吧！
那只能选择自建CA，自签一个证书了！
因为有2个pod，es和kibana，所以要签两张证书，签证书随便用ES的一个版本就可以：
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.4.1-linux-x86_64.tar.gz tar -zxf elasticsearch-8.4.1-linux-x86_64.tar.gz cd elasticsearch-8.4.1/ ./bin/elasticsearch-certutil ca --pem # 得到CA证书，放在当前目录ca目录下 unzip elastic-stack-ca.zip # 生成签发配置文件 cat &lt;&lt; EOF >instances.yml instances: - name: es01 dns: - es01 - localhost ip: - 127.0.0.1 - name: kibana dns: - kibana - localhost ip: - 127.0.0.1 EOF # 签发2个pod的证书 ./bin/elasticsearch-certutil cert --ca-cert ca/ca.crt --ca-key ca/ca.key --pem --in instances.yml # 得到2张证书和key unzip certificate-bundle.zip # 生成两个目录，es01和kibana # 准备好证书目录 mkdir -p /data/elasticsearch/certs mv ca es01 kibana /data/elasticsearch/certs # 准备好持久化卷 mkdir -p /data/elasticsearch/kibanadata mkdir -p /data/elasticsearch/esdata01 二、配置docker-compose.yaml 8.18.6版本的docker-compose.yaml文件，位于：/data/elasticsearch/docker-compose.yaml
...</p></div><footer class=entry-footer><span title='2025-09-02 09:01:11 +0800 CST'>2025年9月2日</span></footer><a class=entry-link aria-label="post link to 生产环境Elasticsearch 8单节点Docker-compose的安装方法" href=https://rendoumi.com/posts/20250902-elasticsearch_single_node_8_setup/></a></article><div class=pagination><ul class=pagination-list><li class="page-item first"><a class=page-link href=/posts/ aria-label="First Page"><span aria-hidden=true>&#9668;</span></a></li><li class="page-item prev"><a class=page-link href=/posts/page/2/ aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/posts/>1</a></li><li class=page-item><a class=page-link href=/posts/page/2/>2</a></li><li class="page-item active"><span class=page-link aria-current=page>3</span></li><li class=page-item><a class=page-link href=/posts/page/4/>4</a></li><li class=page-item><a class=page-link href=/posts/page/5/>5</a></li><li class=page-item><a class=page-link href=/posts/page/6/>6</a></li><li class=page-item><a class=page-link href=/posts/page/7/>7</a></li><li class=page-item><a class=page-link href=/posts/page/8/>8</a></li><li class="page-item next"><a class=page-link href=/posts/page/4/ aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class="page-item last"><a class=page-link href=/posts/page/35/ aria-label="Last Page"><span aria-hidden=true>&#9658;</span></a></li></ul><div class=total-pages>共 35 页</div></div></main><footer class=footer><span>Copyright © 2020-2025 Zhang Ranrui. All Rights Reserved.</span><br>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>