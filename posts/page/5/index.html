<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3988508441804851" crossorigin=anonymous></script><title>所有文章 | 八戒的技术博客</title>
<meta name=keywords content><meta name=description content="所有文章 - 八戒的技术博客"><meta name=author content><link rel=canonical href=https://rendoumi.com/posts/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5d8a858b4ad07d913988e10d3c3dbc8c171f45316a396de8a60d67f44840812d.css integrity="sha256-XYqFi0rQfZE5iOENPD28jBcfRTFqOW3opg1n9EhAgS0=" rel="preload stylesheet" as=style><link rel=icon href=https://rendoumi.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rendoumi.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rendoumi.com/favicon-32x32.png><link rel=apple-touch-icon href=https://rendoumi.com/apple-touch-icon.png><link rel=mask-icon href=https://rendoumi.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://rendoumi.com/posts/index.xml title=rss><link rel=alternate hreflang=zh href=https://rendoumi.com/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rendoumi.com/posts/"><meta property="og:site_name" content="八戒的技术博客"><meta property="og:title" content="所有文章"><meta property="og:locale" content="zh"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="所有文章"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"所有文章","item":"https://rendoumi.com/posts/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://rendoumi.com/ accesskey=h title="八戒的技术博客 (Alt + H)">八戒的技术博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rendoumi.com/ title=首页><span>首页</span></a></li><li><a href=https://rendoumi.com/posts/ title=文章><span class=active>文章</span></a></li><li><a href=https://rendoumi.com/archives/ title=归档><span>归档</span></a></li><li><a href=https://blog.rendoumi.com title=生活><span>生活</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://rendoumi.com/search/ title=搜索><span>搜索</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>所有文章</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Redpanda到期后如何续License
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>上回我们在 Kafka的测试替代品-Redpanda 中说了怎么搭建，结果用了一个月，问题就来了
license过期了，擦的，只允许用30天，需要续费了。
方法如下：
一、打开网站，申请30天的免费license
https://cloud.redpanda.com/try-enterprise
打开网站，然后填入姓名和邮箱，就会得到一个长字符串xyz，拷贝下来
二、去机器上
我们是用docker compose启动的，所以需要进入容器，导入license
docker exec -it redpanda-0 /bin/sh rpk cluster license set xyz 三、重启容器
按道理上一步弄完，就应该好了的，可惜这产品做的稀烂。还必须重启容器才起作用
docker compose restart 就ok了，但是30天就更新一次license，而且必须要重启容器，这谁受得了啊。
下周就抽空装一个不依赖Zookeeper，用Rraft的Kafka来用，彻底去掉这个不伦不类的软件。</p></div><footer class=entry-footer><span title='2025-07-25 09:01:11 +0800 CST'>2025年7月25日</span></footer><a class=entry-link aria-label="post link to Redpanda到期后如何续License" href=https://rendoumi.com/posts/20250725_redpanda_license/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Postgres不同实例、不同用户直接的数据导出导入
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>公司生产环境在AWS使用了 Aurora Postgres Serveless 的数据库。
测试环境是在内网搭建了一个postgres 13数据库。
那测试和生产的实例不同，数据库不同，用户名也不同，需要把测试环境的A库的schema.public迁移到生产B库的schema.public。
普及一下概念，PG的权限分三层，数据库、schema、schema中的对象。
那么用pg_dump的话，如果不带任何参数，那会把权限也给带上，那就麻烦大了去了！
所以正确的导出、导入步骤如下：
一、首先要观察源库，看看都有什么extention，在schema.public有什么Functions
如上图所示，看到uuid_generate
# 看看服务器版本 select version(); PostgreSQL 13.14 那就很奇怪，extension 只有一个plpgsql，functions却有一堆uuid_generate
那十有八九需要用到extension uuid-oosp
先去目的库建一个吧
create extension "uuid-ossp"; 二、dump数据
这里要注意，不要把任何权限的东西带进来
pg_dump -h 172.16.8.1 -U postgres -d source --schema=public --no-owner --no-privileges --file=export.sql # 全备份的命令 # export PGPASSWORD="xxxxxxxx" # pg_dump -U bbc -h localhost -p 5432 bbc > dc_system.sql 然后要编辑看看这个导入的文件
发现有create schema的语句，如果目的数据库已经有了，那需要去掉。
再看下面：
建立了一个FUNCTION，如果已经建立了extension，那也会报错，不过这2种错误我们都可以直接不用管，直接执行试试
三、导入目标库
跑一跑，看一看：
psql -h 10.8.0.1 -U dest -d dest -f export.sql 报了不少错
...</p></div><footer class=entry-footer><span title='2025-07-23 09:01:11 +0800 CST'>2025年7月23日</span></footer><a class=entry-link aria-label="post link to Postgres不同实例、不同用户直接的数据导出导入" href=https://rendoumi.com/posts/20250723-postgres_dump_restore/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>内网kubernetes+cloudflare+cert-manager自动签发证书
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>这个场景非常的有意思：
公司内部有若干个kubernetes集群，属于测试环境，研发搭建了一套SAAS的环境，这个环境需要xxx.abc.com的域名来访问，域名解析记录全都是192.168.0.x，供内部访问，域名会动态生成，需要证书也随之生成，且dns域名托管在cloudflare上。
基本环境如上，麻烦的是 cert-manager 不可能签发私网的证书，只能曲线救国，用dns验证的方式来签发证书了，如果配上 external-dns，那dns解析也不用做了；只要发布一个ingress，就直接生成dns解析记录和对应的https证书。
具体做法如下：
一、配置 cloudflare API token
登录cloudflare，去生成API Token，路径是：User Profile > API Tokens > API Tokens.
Permissions：
Zone - DNS - Edit Zone Resources:
Include - All Zones cert-manager的官方文档居然是错的，https://cert-manager.io/docs/configuration/acme/dns01/cloudflare/
推荐的 Zone - Zone - Read 是加不上的，有Edit就足够了
然后获得Token的字符串xxxxxx
二、安装cert-manager
这个简单，直接用helm安装
现在这个时间节点，2025.07.09，cert-manager 是 v1.18.2，所以用新命令执行安装
helm repo add jetstack https://charts.jetstack.io helm repo update #老版本比如1.0 helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --set installCRDs=true #新版本v1.18.2 helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --set crds.enabled=true 三、准备签发机构Issuer
...</p></div><footer class=entry-footer><span title='2025-07-09 09:01:11 +0800 CST'>2025年7月9日</span></footer><a class=entry-link aria-label="post link to 内网kubernetes+cloudflare+cert-manager自动签发证书" href=https://rendoumi.com/posts/20250709-cert_manager_cloudflare/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>CORS跨域在不同环境中的配置
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>Cross-Origin Resource Sharing (CORS) 跨域，一个网站引用了另外一个网站的资源，就需要跨域了。
最通俗点，就是服务器的返回头上要加上三行：
Access-Control-Allow-Origin", "*" Access-Control-Allow-Methods", "GET, POST, OPTIONS" Access-Control-Allow-Headers", "DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization" 说白点：就是允许的来源站，允许的方法，允许的头信息
那在不同的地方配置又不相同：
一、Nginx server { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization'; 二、openresty中的lua脚本 location /pg/nginit { rewrite_by_lua_block { ngx.log(ngx.ERR, "Environment configuration update, about to get configuration information from redis") -- 添加跨域 CORS 头 ngx.header["Access-Control-Allow-Origin"] = "*" -- 允许所有域名请求 ngx.header["Access-Control-Allow-Methods"] = "GET, POST, OPTIONS" -- 允许的方法 ngx.header["Access-Control-Allow-Headers"] = "DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization" -- 允许的请求头 三、AWS的S3 &lt;CORSConfiguration> &lt;CORSRule> &lt;AllowedOrigin>http://example.com&lt;/AllowedOrigin> &lt;AllowedMethod>GET&lt;/AllowedMethod> &lt;AllowedHeader>*&lt;/AllowedHeader> &lt;/CORSRule> &lt;/CORSConfiguration> 四、AWS Lambda 或者 API Gateway headers: { 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': true, } 最后，AWS的ALB不支持配置CORS！！！，必须在后端的 application 中设置。
...</p></div><footer class=entry-footer><span title='2025-06-17 09:01:11 +0800 CST'>2025年6月17日</span></footer><a class=entry-link aria-label="post link to CORS跨域在不同环境中的配置" href=https://rendoumi.com/posts/20250617-cors/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>AWS的跨账号访问不同VPC域中的服务
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>公司有两个AWS账号，有各自不同的 VPC 域。其中一个账号用到了 Aurora Postgres Serveless 的数据库。
现在另一个账号也需要用到posgres数据库，最直接的想法是在本域再搭一套postgres，或者ec2新加一台，上面安装posgres。
先去检查了一下已有的postgres serverless服务，结果使用率才23%，当下就直接想复用它了。
那能不能单独再开一个db，单独给第二个账号用呢，查了半天资料。可以的，但是吧，chatgpt真的是满嘴胡说八道，连带gemini也是。
aws家的东西都是开源经过魔改，跟网上占大多数的资料是不同的，这直接导致 chatgpt 按照网上大多数文档来进行推理，导致错误！！！
还有就是aws家的东西更新修改很快，最新的文档和之前的文档不同，也导致 chatpt 按照网上大多数的旧文档来进行推理，导致错误！！！
这个东西的架构图如上，右边的VPC里面连着 aurora 服务，它实际是target group的一个目标，然后上联到nlb，nlb再上联到endpoint service，对外提供服务.
然后左面VPC中建endpoint，通过PrivateLink连接到右边的EndpointService，这样通过私有的dns name和security group再进行控制，就可以直接连到右边的endpoint service服务资源了。
具体的做法步骤如下：
一、第一步，右边的VPC中 1、建立EndpointService
到VPC中，左边的Endpoint Services，点击：
点击Create endpoint service新建一个
名字：postgresql-serverless-endpoint-service，由于现在还没有nlb，需要再新建一个；点击Create new load balancer
2、建立nlb
点击：Create load balancer新建
这个类型，只能是nlb
我们这个nlb，不放在公网，不公开，所以选私有的Internal，只有IPV4，不提供IPV6.
网络选该VPC，子网选择三个private的子网
Security groups选择一下，这里rds-sg的inbound规则是允许TCP端口5432的进入，如果没有就新建一个SG
到最后了，居然还没有target group，那又要建一个了，点击Create target group建立
3、建立target group
名字叫做：postgres-target-group
我们选IP addresses，因为要连到后面的postgres服务
然后选好TCP，Port 5432， IPV4，VPC，其它保持缺省，然后建立
...</p></div><footer class=entry-footer><span title='2025-05-21 09:01:11 +0800 CST'>2025年5月21日</span></footer><a class=entry-link aria-label="post link to AWS的跨账号访问不同VPC域中的服务" href=https://rendoumi.com/posts/20250521-aws_endpoint/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>kafka的测试替代品-redpanda
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>公司的一个公网要搬到内网的一个Rancher集群上，很繁琐
原有的架构有kafka，要在内网复现一个出来
那3节点的kafka和3节点的zookeeper，真的是不想搭啊
搜啊搜啊搜啊搜，终于找到若干平替：
Redis 的平替 Dragonfly Mongo 的平替 FerretDB Kafka 的平替 Redpanda 那就选定用Redpanda来搞，方法还是有一些曲折的：
Redpanda 在 2025年5月16日这个节点，有5个版本
最新的25.1的版本，如果用docker compose来启动，是个压缩包，好多文件。
数据盘有三个了，而且用到了minio做后端的持久化卷，这么复杂，那不如直接搞Kafka了
那只能往前回退，选用24.2的版本，docker compose 就一个文件，不过这个版本 2025年7月31日就终结支持了。
下载的话：https://docs.redpanda.com/24.2/get-started/quick-start/
我们要的是一个broker的，那直接给出源文件
name: redpanda-quickstart-one-broker networks: redpanda_network: driver: bridge volumes: redpanda-0: null services: redpanda-0: command: - redpanda - start - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092 # Address the broker advertises to clients that connect to the Kafka API. # Use the internal addresses to connect to the Redpanda brokers' # from inside the same Docker network. # Use the external addresses to connect to the Redpanda brokers' # from outside the Docker network. - --advertise-kafka-addr internal://redpanda-0:9092,external://localhost:19092 - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082 # Address the broker advertises to clients that connect to the HTTP Proxy. - --advertise-pandaproxy-addr internal://redpanda-0:8082,external://localhost:18082 - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081 # Redpanda brokers use the RPC API to communicate with each other internally. - --rpc-addr redpanda-0:33145 - --advertise-rpc-addr redpanda-0:33145 # Mode dev-container uses well-known configuration properties for development in containers. - --mode dev-container # Tells Seastar (the framework Redpanda uses under the hood) to use 1 core on the system. - --smp 1 - --default-log-level=info image: docker.redpanda.com/redpandadata/redpanda:v25.1.4 container_name: redpanda-0 volumes: - redpanda-0:/var/lib/redpanda/data networks: - redpanda_network ports: - 18081:18081 - 18082:18082 - 19092:19092 - 19644:9644 console: container_name: redpanda-console image: docker.redpanda.com/redpandadata/console:v3.1.0 networks: - redpanda_network entrypoint: /bin/sh command: -c 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml; /app/console' environment: CONFIG_FILEPATH: /tmp/config.yml CONSOLE_CONFIG_FILE: | kafka: brokers: ["redpanda-0:9092"] schemaRegistry: enabled: true urls: ["http://redpanda-0:8081"] redpanda: adminApi: enabled: true urls: ["http://redpanda-0:9644"] ports: - 8080:8080 depends_on: - redpanda-0 仔细看了一下，这里面有问题，卷是空的，这可不行，必须持久化到本地，改一下
...</p></div><footer class=entry-footer><span title='2025-05-16 12:01:11 +0800 CST'>2025年5月16日</span></footer><a class=entry-link aria-label="post link to kafka的测试替代品-redpanda" href=https://rendoumi.com/posts/20250516-redpanda/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Ubuntu 如何安装远程桌面RDP
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>非常郁闷的一件事。公司的网络架构非常有意思，灵活性极大。导致我这个总在公司之外用openvpn连进去的人很痛苦，无法复现同事提出的问题。
没办法，需要在公司网络内部有台测试机，那实际是有很多的，但都是debian或者ubuntu的，而问题偏偏是网页打不开的问题。
那就干脆找一台Ubuntu，安装一下远程桌面，用RDP 3389连进去，启动一个Firefox，进行测试即可。
步骤如下：
一、升级ubuntu到最新
sudo apt update sudo apt upgrade -y 二、安装xrdp
sudo apt install xrdp -y 三、安装桌面环境xfce
sudo apt install xfce4 xfce4-goodies -y 四、配置xfce使用xrdp
echo xfce4-session > ~/.xsession # 将最后一行替换掉 sudo vi /etc/xrdp/startwm.sh #exec /bin/sh /etc/X11/Xsession exec startxfce4 五、设置xrdp服务自启动
sudo systemctl enable xrdp sudo systemctl start xrdp 六、如果有防火墙，记得放开3389的tcp端口
七、把用户加入ssl-cert组
# 这里我的登录用户是debian sudo adduser debian ssl-cert # 加组不用重启，如有其它改动需要重启 sudo systemctl restart xrdp 八、安装Firefox
sudo apt install firefox-esr 九、开远程桌面，连上去，开个命令行执行firefox-esr
...</p></div><footer class=entry-footer><span title='2025-05-16 09:01:11 +0800 CST'>2025年5月16日</span></footer><a class=entry-link aria-label="post link to Ubuntu 如何安装远程桌面RDP" href=https://rendoumi.com/posts/20250516-ubuntu_rdp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>mongodb 集群的恢复
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>要做一个mongodb集群的迁移和恢复，真是折腾死人了。记录并顺便吐槽一下：
mongodb的tools真的是太简易、粗糙、丑陋了。
线上的源数据库是腾讯的服务，要废弃搬迁到内网，足足折腾了一个星期。
线上源数据库环境如下：
云数据库 TencentDB 4C/8GB/500GB 3节点 于是在线下对等建立了mongo集群，同样配置，同样3节点。
噩梦由此开始啊，注意线下集群的memory配置一定要高：
32GB 用户名和密码一定要和线上完全一致 如果用户名密码不一致，Document恢复完毕，Index无法建立，因为是完全恢复，会覆盖admin这个db 然后开始dump线上数据
mongodump -vvvvv --uri="mongodb://root:xxxxxxxx@10.1.2.3:27017/?authSource=admin" 然后生成一个24G大小得dump文件夹，压缩后2.4G，传输到线下库上准备恢复
# 大量恢复必须扩大文件句柄，否则过不去 ulimit -n 655360 # 一定要记录下来开始的时间戳，后面有用 date Sun May 11 06:34:02 PM CST 2025 # 开始恢复，漫长的一天开始了 # 必须放到screen中执行，否则网络不好，断了也会很悲剧 screen -L ./mongorestore \ --drop \ --host=192.168.111.222 \ --port=27017 \ --username=root \ --authenticationDatabase=admin \ --nsExclude=admin \ /root/dump ctrl+a+d 其实刚开始线下三节点得配置是8G，然后恢复用了一晚，报错，直接把shard3给打崩了，虽然三节点都是docker启动得，有自动恢复机制，但是mongorestore可不管这个，中断期间有1000个Document没有恢复成功。
重试了2次后才发现这问题，2天已经过去了，意识到就立刻把内存提升到32G，再次进行恢复。
但是新建的集群的密码跟源库这时是不一致的，又一天过去了，Document文档是恢复完毕，Index又无法建立，因为用户名和密码不一致，Fuck！
又双叒再次开始恢复，这下天下大吉了，然后这还不算完！
restore后，其实又过了一天，那要追平之后的数据，就得用上实时同步工具了，这里用的是阿里的mongoshake
下载：
wget https://github.com/alibaba/MongoShake/releases/download/release-v2.8.5-20250403/mongo-shake-v2.8.5.tgz tar zxvf mongo-shake-v2.8.5.tgz cd mongo-shake-v2.8.5 wget https://raw.githubusercontent.com/alibaba/MongoShake/refs/heads/develop/conf/collector.conf 我们需要注意collector.conf的以下地方：
...</p></div><footer class=entry-footer><span title='2025-05-12 09:01:11 +0800 CST'>2025年5月12日</span></footer><a class=entry-link aria-label="post link to mongodb 集群的恢复" href=https://rendoumi.com/posts/20250512-mongodb-restore/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>mongodb 如何升级
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>mongodb 公司现在运行的版本是mongodb 4.2.19，在处理allowDiskUse的时候失败
对比了一下，似乎另外一个集群跑的是5.0.5，就没有问题
那就升级一下，步骤如下：
首先下载 5.0.30
wget --no-check-certificate https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-debian11-5.0.30.tgz 然后解压弄好，准备好mongodb.conf
dump下来老数据，不加·–quiet·的参数有可能会遇到EOF的错误
mkdir mongobackup cd mongobackup mongodump --quiet 然后杀掉4.2.19，启动5.0.30，把数据回灌回去，同样要用--quiet参数
cd mongobackup mongorestore --quiet 这样就OK了。
注意，mongo 是吃内存大户，如果备份不下来，或者恢复不进去，请增加内存。
曾有过一次，8G->16G->32G 才成功。
而且必须一个一个db进行备份，一个一个db进行恢复，记得备份 admin 数据库
mongodump -d message mongorestore --port 37017 --drop --nsInclude=message.*</p></div><footer class=entry-footer><span title='2025-01-22 09:01:11 +0800 CST'>2025年1月22日</span></footer><a class=entry-link aria-label="post link to mongodb 如何升级" href=https://rendoumi.com/posts/20250122-mongodb_upgrade/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>AWS alb 负载均衡做ingress的注意事项
<span class=entry-hint title=Draft><svg height="20" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h2></header><div class=entry-content><p>管理了一个AWS的EKS集群，用的是ALB的负载均衡，这个负载均衡和Nginx有区别，有很多特殊的地方需要注意。
基本需要宣告很多独有的 annotations
一、http自动跳转到https annotations: alb.ingress.kubernetes.io/actions.ssl-redirect: | {"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}} ...... - host: '*.bajie.dev' http: paths: - backend: service: name: ssl-redirect port: name: use-annotation path: / pathType: Prefix 注意，annotation了上面一条，那么在LB中，http 80的规则就只剩下这一条了，压倒一切的规则。
之后你再annotation别的http规则，会不生效；你只能去annotition https的规则。
二、www重定向 例子： 输入 rendoumi.com，会自动重定义到 www.rendoumi.com
annotations: alb.ingress.kubernetes.io/actions.www-redirect: | {"type":"redirect","redirectConfig":{"host":"www.rendoumi.com","port":"443","protocol":"HTTPS","statusCode":"HTTP_301"}} ...... - host: rendoumi.com http: paths: - backend: service: name: www-redirect port: name: use-annotation path: / pathType: Prefix 这个是直接301跳转到https去了
...</p></div><footer class=entry-footer><span title='2025-01-20 09:01:11 +0800 CST'>2025年1月20日</span></footer><a class=entry-link aria-label="post link to AWS alb 负载均衡做ingress的注意事项" href=https://rendoumi.com/posts/20250120-aws_alb_ingress/></a></article><div class=pagination><ul class=pagination-list><li class="page-item first"><a class=page-link href=/posts/ aria-label="First Page"><span aria-hidden=true>&#9668;</span></a></li><li class="page-item prev"><a class=page-link href=/posts/page/4/ aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/posts/>1</a></li><li class=page-item><a class=page-link href=/posts/page/2/>2</a></li><li class=page-item><a class=page-link href=/posts/page/3/>3</a></li><li class=page-item><a class=page-link href=/posts/page/4/>4</a></li><li class="page-item active"><span class=page-link aria-current=page>5</span></li><li class=page-item><a class=page-link href=/posts/page/6/>6</a></li><li class=page-item><a class=page-link href=/posts/page/7/>7</a></li><li class=page-item><a class=page-link href=/posts/page/8/>8</a></li><li class="page-item next"><a class=page-link href=/posts/page/6/ aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class="page-item last"><a class=page-link href=/posts/page/35/ aria-label="Last Page"><span aria-hidden=true>&#9658;</span></a></li></ul><div class=total-pages>共 35 页</div></div></main><footer class=footer><span>Copyright © 2020-2025 Zhang Ranrui. All Rights Reserved.</span><br>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>